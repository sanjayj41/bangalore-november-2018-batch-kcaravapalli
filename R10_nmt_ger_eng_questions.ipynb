{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nmt_ger-eng_questions.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ueeUkE9Pvs91"
      },
      "source": [
        "# Neural Machine Translation\n",
        "\n",
        "- Translate a given sentence in one language to another desired language.\n",
        "\n",
        "#### In this notebook, we aim to build a model which can translate German sentences to English."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru4LkWfKyrjp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HphxvZ0fv_kr"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "Dataset is taken from http://www.manythings.org/anki/.\n",
        "\n",
        "We are considering German – English deu-eng.zip file from the above mentioned website.\n",
        "\n",
        "In the above zip file there is a file with name **`deu.txt`** that contains **152,820** pairs of English to German phrases, one pair per line with a tab separating the phrases.\n",
        "\n",
        "\n",
        "For example,\n",
        "\n",
        "The first 5 lines in deu.txt are as given below.\n",
        "\n",
        "***\n",
        "```\n",
        "Hi.    Hallo!\n",
        "Hi.    Grüß Gott!\n",
        "Run!    Lauf!\n",
        "Wow!    Potzdonner!\n",
        "Wow!    Donnerwetter!\n",
        "```\n",
        "***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KzhjY_3MxlCT"
      },
      "source": [
        "## Problem\n",
        "\n",
        "### Given a sequence of words in German as input, predict the sequence of words in English."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "STq1sKSHywCQ"
      },
      "source": [
        "### 1. Prepare Data\n",
        "\n",
        "\n",
        "The preprocessing of the data involves:\n",
        "\n",
        "1. Removing punctuation marks from the data.\n",
        "\n",
        "2. Converting text corpus into lower case characters.\n",
        "\n",
        "3. Split into Train and Test sets.\n",
        "\n",
        "4. Shuffling the sentences.\n",
        "\n",
        "\n",
        "\n",
        "The above tasks are done  and full dataset is given as **``english-german-both.pkl``** respectively.\n",
        "\n",
        "Download dataset files from here: https://drive.google.com/open?id=1gWVk7SuuE93Cf_nT9Lb7GBCiwfAgdBiX\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "x9JDfVgWosMJ"
      },
      "source": [
        "# Character level Machine Translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sP4P2nnAXD5G",
        "colab_type": "text"
      },
      "source": [
        "## Initialize parameters\n",
        "Run the below code to initialize the variables required for the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4jRTxBQ9owHH",
        "colab": {}
      },
      "source": [
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 10  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
        "num_samples = 10000  # Number of samples to train on.\n",
        "# Path to the data txt file on disk.\n",
        "data_path = 'fra.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0N1Q-zzUJtO0"
      },
      "source": [
        "### Connect to google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SEtf-c5Fo7eF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "97a343c5-e2b3-49ff-912e-14083c8b9ee4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Mv0XAJSZJyOl"
      },
      "source": [
        "### Give the path for the folder in which the dataset is present in google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fXQOArlSo8SX",
        "colab": {}
      },
      "source": [
        "project_path = '/content/drive/My Drive/AIML/Assignments/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoEhVDh3qfuj",
        "colab_type": "text"
      },
      "source": [
        "### Change present working directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-plftRTqlgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(project_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GkAdNgJrKDvK"
      },
      "source": [
        "## Load the pickle file (`english-german-both.pkl`) into a variable with name `dataset`\n",
        "Run the below code to load the .pkl file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a8fpd1Lxo8VH",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open(project_path + 'english-german-both.pkl', 'rb') as f:\n",
        "  dataset = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9pkL351SKaWb"
      },
      "source": [
        "## Check the `dataset` variable at this step. It should be as given below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D6kEL_65KmHe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "941ee7c0-39a0-4944-8aba-bc65fefdd753"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['stay with us', 'bleib bei uns'],\n",
              "       ['she wants him', 'sie will ihn'],\n",
              "       ['youre strong', 'du bist stark'],\n",
              "       ...,\n",
              "       ['i thought so', 'das dachte ich mir'],\n",
              "       ['keep warm', 'haltet euch warm'],\n",
              "       ['im sick', 'ich bin krank']], dtype='<U291')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uQ270GmwK2Qt"
      },
      "source": [
        "## Feature set and target set division from the **dataset**\n",
        "\n",
        "### Run the below code to divide the dataset into feature set(input) and target set(output). \n",
        "\n",
        "1. We are creating two lists for storing input sentences and output sentences separately. \n",
        "2. We are storing each character in a list from both input and target sets separately. \n",
        "3. Print and check `input_texts` and `target_texts`.\n",
        "4. Print and check `input_characters` and `target_characters`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fJ95hstto8Xy",
        "colab": {}
      },
      "source": [
        "# Vectorize the data.\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "\n",
        "for line in dataset[: min(num_samples, len(dataset) - 1)]:\n",
        "    input_text, target_text = line[0], line[1]\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = '\\t' + target_text + '\\n'\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwWZMeVjlPjB",
        "colab_type": "text"
      },
      "source": [
        "### Print input text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S-1OyZSULuJY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12401002-ab14-4bdc-96b8-b8acbbf6eb30"
      },
      "source": [
        "input_texts[1:2]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['she wants him']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo7Mno1JlVWP",
        "colab_type": "text"
      },
      "source": [
        "### Print target text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_pnLXkk8LzBx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10f38984-c62a-435e-ab1a-c3110eb283c4"
      },
      "source": [
        "target_texts[1:2]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\tsie will ihn\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7IhmN_hlb1K",
        "colab_type": "text"
      },
      "source": [
        "### Print input character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9az5VYFjNe7I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "1e0fa158-d13f-4add-ee59-277dd5254174"
      },
      "source": [
        "input_characters"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CX30Y8dZlfGQ",
        "colab_type": "text"
      },
      "source": [
        "### Print target character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kxg3509lNjnU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "6a23d4ec-ca75-4c39-fa8e-d7a8b5ec22e8"
      },
      "source": [
        "target_characters"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\t',\n",
              " '\\n',\n",
              " ' ',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Dw10uDT3Oc1N"
      },
      "source": [
        "## Stats from the dataset\n",
        "\n",
        "### Run the below code to check the stats from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T4stnzMpo8ci",
        "colab": {}
      },
      "source": [
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VfbreAAUo8e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "e997c777-eafc-4134-f27f-6716dbfebeee"
      },
      "source": [
        "print('Number of samples:', len(input_texts))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)\n",
        "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
        "print('Max sequence length for outputs:', max_decoder_seq_length)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 9999\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 29\n",
            "Max sequence length for inputs: 15\n",
            "Max sequence length for outputs: 51\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mVuwMY0UTVKD"
      },
      "source": [
        "## Build character to index dictionary names `input_token_index` and `target_token_index` for input and target sets respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QYXSW9zOo8hl",
        "colab": {}
      },
      "source": [
        "input_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict(\n",
        "    [(char, i) for i, char in enumerate(target_characters)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aUS5gEamGiC",
        "colab_type": "text"
      },
      "source": [
        "### Print input_index_token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "__ga4KfKTijk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "20cd3bda-67aa-4b04-fd1e-12a679058a83"
      },
      "source": [
        "input_token_index"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " 'a': 1,\n",
              " 'b': 2,\n",
              " 'c': 3,\n",
              " 'd': 4,\n",
              " 'e': 5,\n",
              " 'f': 6,\n",
              " 'g': 7,\n",
              " 'h': 8,\n",
              " 'i': 9,\n",
              " 'j': 10,\n",
              " 'k': 11,\n",
              " 'l': 12,\n",
              " 'm': 13,\n",
              " 'n': 14,\n",
              " 'o': 15,\n",
              " 'p': 16,\n",
              " 'q': 17,\n",
              " 'r': 18,\n",
              " 's': 19,\n",
              " 't': 20,\n",
              " 'u': 21,\n",
              " 'v': 22,\n",
              " 'w': 23,\n",
              " 'x': 24,\n",
              " 'y': 25,\n",
              " 'z': 26}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGs66ZhjmNBA",
        "colab_type": "text"
      },
      "source": [
        "### Print target_token_index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sa3DArDrTm1z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "8eb893a1-db96-47bd-fb2f-86e85d7a865d"
      },
      "source": [
        "target_token_index"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\t': 0,\n",
              " '\\n': 1,\n",
              " ' ': 2,\n",
              " 'a': 3,\n",
              " 'b': 4,\n",
              " 'c': 5,\n",
              " 'd': 6,\n",
              " 'e': 7,\n",
              " 'f': 8,\n",
              " 'g': 9,\n",
              " 'h': 10,\n",
              " 'i': 11,\n",
              " 'j': 12,\n",
              " 'k': 13,\n",
              " 'l': 14,\n",
              " 'm': 15,\n",
              " 'n': 16,\n",
              " 'o': 17,\n",
              " 'p': 18,\n",
              " 'q': 19,\n",
              " 'r': 20,\n",
              " 's': 21,\n",
              " 't': 22,\n",
              " 'u': 23,\n",
              " 'v': 24,\n",
              " 'w': 25,\n",
              " 'x': 26,\n",
              " 'y': 27,\n",
              " 'z': 28}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UB7uI724TrlM"
      },
      "source": [
        "## Build Model\n",
        "Initialize the required layers from keras\n",
        "\n",
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T1GuGnDiqOz3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6cca49b9-3d31-4acc-c07f-4205734c0d25"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, Dense\n",
        "import numpy as np"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3q9GVu-pT9UR"
      },
      "source": [
        "### Run the below code to build one-hot vectors for the characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uatzEBy5qIpI",
        "colab": {}
      },
      "source": [
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype='float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tDJkGbp078A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "489888fe-aa05-42ba-e2e6-26046d6964cb"
      },
      "source": [
        "print(encoder_input_data.shape)\n",
        "print(decoder_input_data.shape)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9999, 15, 27)\n",
            "(9999, 51, 29)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MDGoIZXuqLF7",
        "colab": {}
      },
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i0ihyyfeW7le"
      },
      "source": [
        "### Build the encoder Model\n",
        "\n",
        "Define an input sequence and process it.\n",
        "\n",
        "Discard `encoder_outputs` and only keep the states."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CQU4zjxdqXnG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e289016d-df0f-4c56-fa8e-7d8f0843a187"
      },
      "source": [
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder=LSTM(latent_dim,return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0811 08:27:41.645276 140325880854400 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZkzkZfQy1j6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_states = [state_h, state_c]\n",
        "encoder_model = Model(encoder_inputs, encoder_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "X3PzX5oBXfGW"
      },
      "source": [
        "### Build the decoder Model\n",
        "\n",
        "Set up the decoder, using `encoder_states` as initial state.\n",
        "\n",
        "We set up our decoder to return full output sequences, and to return internal states as well. We don't use the return states in the training model, but we will use them in inference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ytn5MNCjqZuc",
        "colab": {}
      },
      "source": [
        "decoder_inputs = Input(shape=(None,num_decoder_tokens))\n",
        "decoder_lstm = LSTM(latent_dim,return_state=True,return_sequences=True)\n",
        "\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpJnlQgvn8vN",
        "colab_type": "text"
      },
      "source": [
        "### Define Model\n",
        "\n",
        "Define the model that will turn `encoder_input_data ` & ` decoder_input_data` into `decoder_target_data`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E24IW9wIqcYq",
        "colab": {}
      },
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qvawc6CfXkzG"
      },
      "source": [
        "### Compile and fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vhXLFmApqeU4",
        "colab": {}
      },
      "source": [
        "from keras import metrics\n",
        "model.compile(optimizer='rmsprop', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=[metrics.categorical_accuracy])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeN8WIzxz9mK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7267148e-fa22-451b-f4b7-389c588ffd8f"
      },
      "source": [
        "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=batch_size,\n",
        "          epochs=500,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0811 08:40:49.694081 140325880854400 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0811 08:40:50.865717 140325880854400 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 7999 samples, validate on 2000 samples\n",
            "Epoch 1/500\n",
            "7999/7999 [==============================] - 16s 2ms/step - loss: 0.9606 - categorical_accuracy: 0.0866 - val_loss: 0.8149 - val_categorical_accuracy: 0.1314\n",
            "Epoch 2/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.7460 - categorical_accuracy: 0.1494 - val_loss: 0.6896 - val_categorical_accuracy: 0.1571\n",
            "Epoch 3/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.6470 - categorical_accuracy: 0.1738 - val_loss: 0.5988 - val_categorical_accuracy: 0.1795\n",
            "Epoch 4/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.5893 - categorical_accuracy: 0.1891 - val_loss: 0.5662 - val_categorical_accuracy: 0.1868\n",
            "Epoch 5/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.5520 - categorical_accuracy: 0.1998 - val_loss: 0.5321 - val_categorical_accuracy: 0.1998\n",
            "Epoch 6/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.5231 - categorical_accuracy: 0.2082 - val_loss: 0.5101 - val_categorical_accuracy: 0.2051\n",
            "Epoch 7/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.5000 - categorical_accuracy: 0.2149 - val_loss: 0.4911 - val_categorical_accuracy: 0.2120\n",
            "Epoch 8/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.4795 - categorical_accuracy: 0.2210 - val_loss: 0.4768 - val_categorical_accuracy: 0.2150\n",
            "Epoch 9/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.4609 - categorical_accuracy: 0.2267 - val_loss: 0.4617 - val_categorical_accuracy: 0.2198\n",
            "Epoch 10/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.4444 - categorical_accuracy: 0.2317 - val_loss: 0.4493 - val_categorical_accuracy: 0.2246\n",
            "Epoch 11/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.4288 - categorical_accuracy: 0.2366 - val_loss: 0.4381 - val_categorical_accuracy: 0.2271\n",
            "Epoch 12/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.4150 - categorical_accuracy: 0.2406 - val_loss: 0.4301 - val_categorical_accuracy: 0.2298\n",
            "Epoch 13/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.4018 - categorical_accuracy: 0.2452 - val_loss: 0.4208 - val_categorical_accuracy: 0.2331\n",
            "Epoch 14/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.3888 - categorical_accuracy: 0.2487 - val_loss: 0.4122 - val_categorical_accuracy: 0.2365\n",
            "Epoch 15/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.3772 - categorical_accuracy: 0.2526 - val_loss: 0.4043 - val_categorical_accuracy: 0.2390\n",
            "Epoch 16/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.3661 - categorical_accuracy: 0.2560 - val_loss: 0.4031 - val_categorical_accuracy: 0.2394\n",
            "Epoch 17/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.3551 - categorical_accuracy: 0.2595 - val_loss: 0.3967 - val_categorical_accuracy: 0.2407\n",
            "Epoch 18/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.3448 - categorical_accuracy: 0.2622 - val_loss: 0.3934 - val_categorical_accuracy: 0.2428\n",
            "Epoch 19/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.3350 - categorical_accuracy: 0.2655 - val_loss: 0.3884 - val_categorical_accuracy: 0.2450\n",
            "Epoch 20/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.3258 - categorical_accuracy: 0.2681 - val_loss: 0.3857 - val_categorical_accuracy: 0.2454\n",
            "Epoch 21/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.3166 - categorical_accuracy: 0.2714 - val_loss: 0.3850 - val_categorical_accuracy: 0.2462\n",
            "Epoch 22/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.3080 - categorical_accuracy: 0.2739 - val_loss: 0.3808 - val_categorical_accuracy: 0.2479\n",
            "Epoch 23/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.2996 - categorical_accuracy: 0.2766 - val_loss: 0.3822 - val_categorical_accuracy: 0.2479\n",
            "Epoch 24/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.2914 - categorical_accuracy: 0.2789 - val_loss: 0.3802 - val_categorical_accuracy: 0.2487\n",
            "Epoch 25/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.2835 - categorical_accuracy: 0.2815 - val_loss: 0.3779 - val_categorical_accuracy: 0.2505\n",
            "Epoch 26/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.2762 - categorical_accuracy: 0.2838 - val_loss: 0.3785 - val_categorical_accuracy: 0.2498\n",
            "Epoch 27/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.2688 - categorical_accuracy: 0.2860 - val_loss: 0.3757 - val_categorical_accuracy: 0.2509\n",
            "Epoch 28/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.2616 - categorical_accuracy: 0.2884 - val_loss: 0.3808 - val_categorical_accuracy: 0.2501\n",
            "Epoch 29/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.2545 - categorical_accuracy: 0.2903 - val_loss: 0.3801 - val_categorical_accuracy: 0.2519\n",
            "Epoch 30/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.2480 - categorical_accuracy: 0.2926 - val_loss: 0.3803 - val_categorical_accuracy: 0.2510\n",
            "Epoch 31/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.2413 - categorical_accuracy: 0.2945 - val_loss: 0.3820 - val_categorical_accuracy: 0.2514\n",
            "Epoch 32/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.2356 - categorical_accuracy: 0.2960 - val_loss: 0.3806 - val_categorical_accuracy: 0.2528\n",
            "Epoch 33/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.2297 - categorical_accuracy: 0.2982 - val_loss: 0.3865 - val_categorical_accuracy: 0.2513\n",
            "Epoch 34/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.2238 - categorical_accuracy: 0.2998 - val_loss: 0.3890 - val_categorical_accuracy: 0.2522\n",
            "Epoch 35/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.2182 - categorical_accuracy: 0.3018 - val_loss: 0.3889 - val_categorical_accuracy: 0.2524\n",
            "Epoch 36/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.2124 - categorical_accuracy: 0.3033 - val_loss: 0.3940 - val_categorical_accuracy: 0.2516\n",
            "Epoch 37/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.2079 - categorical_accuracy: 0.3050 - val_loss: 0.3911 - val_categorical_accuracy: 0.2523\n",
            "Epoch 38/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.2022 - categorical_accuracy: 0.3064 - val_loss: 0.3971 - val_categorical_accuracy: 0.2525\n",
            "Epoch 39/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.1976 - categorical_accuracy: 0.3077 - val_loss: 0.4001 - val_categorical_accuracy: 0.2517\n",
            "Epoch 40/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.1933 - categorical_accuracy: 0.3096 - val_loss: 0.3997 - val_categorical_accuracy: 0.2536\n",
            "Epoch 41/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.1885 - categorical_accuracy: 0.3106 - val_loss: 0.4018 - val_categorical_accuracy: 0.2533\n",
            "Epoch 42/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.1844 - categorical_accuracy: 0.3121 - val_loss: 0.4034 - val_categorical_accuracy: 0.2538\n",
            "Epoch 43/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.1800 - categorical_accuracy: 0.3133 - val_loss: 0.4076 - val_categorical_accuracy: 0.2536\n",
            "Epoch 44/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.1760 - categorical_accuracy: 0.3143 - val_loss: 0.4094 - val_categorical_accuracy: 0.2532\n",
            "Epoch 45/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.1720 - categorical_accuracy: 0.3154 - val_loss: 0.4134 - val_categorical_accuracy: 0.2535\n",
            "Epoch 46/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.1687 - categorical_accuracy: 0.3166 - val_loss: 0.4167 - val_categorical_accuracy: 0.2533\n",
            "Epoch 47/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.1644 - categorical_accuracy: 0.3179 - val_loss: 0.4185 - val_categorical_accuracy: 0.2537\n",
            "Epoch 48/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.1616 - categorical_accuracy: 0.3186 - val_loss: 0.4180 - val_categorical_accuracy: 0.2549\n",
            "Epoch 49/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.1577 - categorical_accuracy: 0.3198 - val_loss: 0.4248 - val_categorical_accuracy: 0.2540\n",
            "Epoch 50/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.1544 - categorical_accuracy: 0.3211 - val_loss: 0.4265 - val_categorical_accuracy: 0.2541\n",
            "Epoch 51/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.1511 - categorical_accuracy: 0.3218 - val_loss: 0.4298 - val_categorical_accuracy: 0.2537\n",
            "Epoch 52/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.1481 - categorical_accuracy: 0.3228 - val_loss: 0.4308 - val_categorical_accuracy: 0.2541\n",
            "Epoch 53/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.1454 - categorical_accuracy: 0.3234 - val_loss: 0.4358 - val_categorical_accuracy: 0.2534\n",
            "Epoch 54/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.1423 - categorical_accuracy: 0.3242 - val_loss: 0.4364 - val_categorical_accuracy: 0.2541\n",
            "Epoch 55/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.1395 - categorical_accuracy: 0.3254 - val_loss: 0.4429 - val_categorical_accuracy: 0.2536\n",
            "Epoch 56/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.1369 - categorical_accuracy: 0.3257 - val_loss: 0.4461 - val_categorical_accuracy: 0.2542\n",
            "Epoch 57/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.1342 - categorical_accuracy: 0.3270 - val_loss: 0.4506 - val_categorical_accuracy: 0.2536\n",
            "Epoch 58/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.1317 - categorical_accuracy: 0.3276 - val_loss: 0.4504 - val_categorical_accuracy: 0.2540\n",
            "Epoch 59/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.1290 - categorical_accuracy: 0.3282 - val_loss: 0.4528 - val_categorical_accuracy: 0.2542\n",
            "Epoch 60/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.1264 - categorical_accuracy: 0.3293 - val_loss: 0.4555 - val_categorical_accuracy: 0.2542\n",
            "Epoch 61/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.1242 - categorical_accuracy: 0.3297 - val_loss: 0.4607 - val_categorical_accuracy: 0.2533\n",
            "Epoch 62/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.1219 - categorical_accuracy: 0.3303 - val_loss: 0.4621 - val_categorical_accuracy: 0.2539\n",
            "Epoch 63/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.1194 - categorical_accuracy: 0.3310 - val_loss: 0.4627 - val_categorical_accuracy: 0.2541\n",
            "Epoch 64/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.1174 - categorical_accuracy: 0.3316 - val_loss: 0.4701 - val_categorical_accuracy: 0.2543\n",
            "Epoch 65/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.1151 - categorical_accuracy: 0.3324 - val_loss: 0.4708 - val_categorical_accuracy: 0.2546\n",
            "Epoch 66/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.1133 - categorical_accuracy: 0.3329 - val_loss: 0.4787 - val_categorical_accuracy: 0.2538\n",
            "Epoch 67/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.1111 - categorical_accuracy: 0.3336 - val_loss: 0.4795 - val_categorical_accuracy: 0.2542\n",
            "Epoch 68/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.1094 - categorical_accuracy: 0.3342 - val_loss: 0.4793 - val_categorical_accuracy: 0.2536\n",
            "Epoch 69/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.1071 - categorical_accuracy: 0.3347 - val_loss: 0.4853 - val_categorical_accuracy: 0.2539\n",
            "Epoch 70/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.1055 - categorical_accuracy: 0.3351 - val_loss: 0.4895 - val_categorical_accuracy: 0.2536\n",
            "Epoch 71/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.1043 - categorical_accuracy: 0.3355 - val_loss: 0.4895 - val_categorical_accuracy: 0.2540\n",
            "Epoch 72/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.1015 - categorical_accuracy: 0.3361 - val_loss: 0.4880 - val_categorical_accuracy: 0.2541\n",
            "Epoch 73/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.1002 - categorical_accuracy: 0.3366 - val_loss: 0.4960 - val_categorical_accuracy: 0.2544\n",
            "Epoch 74/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0977 - categorical_accuracy: 0.3374 - val_loss: 0.5035 - val_categorical_accuracy: 0.2533\n",
            "Epoch 75/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0967 - categorical_accuracy: 0.3379 - val_loss: 0.5013 - val_categorical_accuracy: 0.2542\n",
            "Epoch 76/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0947 - categorical_accuracy: 0.3383 - val_loss: 0.5061 - val_categorical_accuracy: 0.2540\n",
            "Epoch 77/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0932 - categorical_accuracy: 0.3385 - val_loss: 0.5051 - val_categorical_accuracy: 0.2547\n",
            "Epoch 78/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0914 - categorical_accuracy: 0.3394 - val_loss: 0.5097 - val_categorical_accuracy: 0.2542\n",
            "Epoch 79/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0902 - categorical_accuracy: 0.3394 - val_loss: 0.5133 - val_categorical_accuracy: 0.2542\n",
            "Epoch 80/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0886 - categorical_accuracy: 0.3400 - val_loss: 0.5176 - val_categorical_accuracy: 0.2534\n",
            "Epoch 81/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0871 - categorical_accuracy: 0.3403 - val_loss: 0.5221 - val_categorical_accuracy: 0.2532\n",
            "Epoch 82/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0853 - categorical_accuracy: 0.3408 - val_loss: 0.5280 - val_categorical_accuracy: 0.2533\n",
            "Epoch 83/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0843 - categorical_accuracy: 0.3412 - val_loss: 0.5278 - val_categorical_accuracy: 0.2540\n",
            "Epoch 84/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0822 - categorical_accuracy: 0.3418 - val_loss: 0.5351 - val_categorical_accuracy: 0.2529\n",
            "Epoch 85/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0812 - categorical_accuracy: 0.3421 - val_loss: 0.5329 - val_categorical_accuracy: 0.2531\n",
            "Epoch 86/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0800 - categorical_accuracy: 0.3426 - val_loss: 0.5374 - val_categorical_accuracy: 0.2529\n",
            "Epoch 87/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0783 - categorical_accuracy: 0.3429 - val_loss: 0.5396 - val_categorical_accuracy: 0.2530\n",
            "Epoch 88/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0770 - categorical_accuracy: 0.3435 - val_loss: 0.5397 - val_categorical_accuracy: 0.2538\n",
            "Epoch 89/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0757 - categorical_accuracy: 0.3438 - val_loss: 0.5475 - val_categorical_accuracy: 0.2532\n",
            "Epoch 90/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.0742 - categorical_accuracy: 0.3442 - val_loss: 0.5476 - val_categorical_accuracy: 0.2535\n",
            "Epoch 91/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0733 - categorical_accuracy: 0.3446 - val_loss: 0.5541 - val_categorical_accuracy: 0.2523\n",
            "Epoch 92/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0721 - categorical_accuracy: 0.3448 - val_loss: 0.5560 - val_categorical_accuracy: 0.2532\n",
            "Epoch 93/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0710 - categorical_accuracy: 0.3451 - val_loss: 0.5539 - val_categorical_accuracy: 0.2544\n",
            "Epoch 94/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0695 - categorical_accuracy: 0.3456 - val_loss: 0.5598 - val_categorical_accuracy: 0.2529\n",
            "Epoch 95/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0682 - categorical_accuracy: 0.3459 - val_loss: 0.5634 - val_categorical_accuracy: 0.2529\n",
            "Epoch 96/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0671 - categorical_accuracy: 0.3462 - val_loss: 0.5666 - val_categorical_accuracy: 0.2533\n",
            "Epoch 97/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0664 - categorical_accuracy: 0.3465 - val_loss: 0.5655 - val_categorical_accuracy: 0.2538\n",
            "Epoch 98/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0649 - categorical_accuracy: 0.3468 - val_loss: 0.5720 - val_categorical_accuracy: 0.2523\n",
            "Epoch 99/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0639 - categorical_accuracy: 0.3473 - val_loss: 0.5760 - val_categorical_accuracy: 0.2531\n",
            "Epoch 100/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0628 - categorical_accuracy: 0.3476 - val_loss: 0.5784 - val_categorical_accuracy: 0.2540\n",
            "Epoch 101/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0619 - categorical_accuracy: 0.3480 - val_loss: 0.5782 - val_categorical_accuracy: 0.2529\n",
            "Epoch 102/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0610 - categorical_accuracy: 0.3482 - val_loss: 0.5830 - val_categorical_accuracy: 0.2528\n",
            "Epoch 103/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0598 - categorical_accuracy: 0.3481 - val_loss: 0.5865 - val_categorical_accuracy: 0.2526\n",
            "Epoch 104/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0588 - categorical_accuracy: 0.3489 - val_loss: 0.5909 - val_categorical_accuracy: 0.2528\n",
            "Epoch 105/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0577 - categorical_accuracy: 0.3491 - val_loss: 0.5931 - val_categorical_accuracy: 0.2525\n",
            "Epoch 106/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0574 - categorical_accuracy: 0.3493 - val_loss: 0.5931 - val_categorical_accuracy: 0.2530\n",
            "Epoch 107/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0559 - categorical_accuracy: 0.3496 - val_loss: 0.5994 - val_categorical_accuracy: 0.2533\n",
            "Epoch 108/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0555 - categorical_accuracy: 0.3497 - val_loss: 0.5981 - val_categorical_accuracy: 0.2533\n",
            "Epoch 109/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0549 - categorical_accuracy: 0.3499 - val_loss: 0.5985 - val_categorical_accuracy: 0.2532\n",
            "Epoch 110/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0534 - categorical_accuracy: 0.3502 - val_loss: 0.6027 - val_categorical_accuracy: 0.2528\n",
            "Epoch 111/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0532 - categorical_accuracy: 0.3504 - val_loss: 0.6046 - val_categorical_accuracy: 0.2530\n",
            "Epoch 112/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0519 - categorical_accuracy: 0.3509 - val_loss: 0.6093 - val_categorical_accuracy: 0.2533\n",
            "Epoch 113/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0513 - categorical_accuracy: 0.3510 - val_loss: 0.6080 - val_categorical_accuracy: 0.2533\n",
            "Epoch 114/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0505 - categorical_accuracy: 0.3514 - val_loss: 0.6151 - val_categorical_accuracy: 0.2524\n",
            "Epoch 115/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0493 - categorical_accuracy: 0.3515 - val_loss: 0.6177 - val_categorical_accuracy: 0.2531\n",
            "Epoch 116/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0492 - categorical_accuracy: 0.3514 - val_loss: 0.6174 - val_categorical_accuracy: 0.2536\n",
            "Epoch 117/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0482 - categorical_accuracy: 0.3519 - val_loss: 0.6171 - val_categorical_accuracy: 0.2529\n",
            "Epoch 118/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0474 - categorical_accuracy: 0.3521 - val_loss: 0.6228 - val_categorical_accuracy: 0.2529\n",
            "Epoch 119/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0464 - categorical_accuracy: 0.3526 - val_loss: 0.6296 - val_categorical_accuracy: 0.2524\n",
            "Epoch 120/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0460 - categorical_accuracy: 0.3524 - val_loss: 0.6300 - val_categorical_accuracy: 0.2535\n",
            "Epoch 121/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.0456 - categorical_accuracy: 0.3526 - val_loss: 0.6323 - val_categorical_accuracy: 0.2521\n",
            "Epoch 122/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0448 - categorical_accuracy: 0.3531 - val_loss: 0.6374 - val_categorical_accuracy: 0.2523\n",
            "Epoch 123/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0442 - categorical_accuracy: 0.3531 - val_loss: 0.6359 - val_categorical_accuracy: 0.2537\n",
            "Epoch 124/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0436 - categorical_accuracy: 0.3532 - val_loss: 0.6367 - val_categorical_accuracy: 0.2529\n",
            "Epoch 125/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0428 - categorical_accuracy: 0.3536 - val_loss: 0.6413 - val_categorical_accuracy: 0.2519\n",
            "Epoch 126/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0425 - categorical_accuracy: 0.3537 - val_loss: 0.6476 - val_categorical_accuracy: 0.2526\n",
            "Epoch 127/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0415 - categorical_accuracy: 0.3539 - val_loss: 0.6449 - val_categorical_accuracy: 0.2523\n",
            "Epoch 128/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0413 - categorical_accuracy: 0.3539 - val_loss: 0.6490 - val_categorical_accuracy: 0.2516\n",
            "Epoch 129/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0408 - categorical_accuracy: 0.3543 - val_loss: 0.6498 - val_categorical_accuracy: 0.2524\n",
            "Epoch 130/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0399 - categorical_accuracy: 0.3545 - val_loss: 0.6535 - val_categorical_accuracy: 0.2518\n",
            "Epoch 131/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0398 - categorical_accuracy: 0.3544 - val_loss: 0.6527 - val_categorical_accuracy: 0.2519\n",
            "Epoch 132/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0396 - categorical_accuracy: 0.3545 - val_loss: 0.6583 - val_categorical_accuracy: 0.2522\n",
            "Epoch 133/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0387 - categorical_accuracy: 0.3548 - val_loss: 0.6587 - val_categorical_accuracy: 0.2527\n",
            "Epoch 134/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0386 - categorical_accuracy: 0.3548 - val_loss: 0.6594 - val_categorical_accuracy: 0.2524\n",
            "Epoch 135/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0383 - categorical_accuracy: 0.3549 - val_loss: 0.6594 - val_categorical_accuracy: 0.2521\n",
            "Epoch 136/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0378 - categorical_accuracy: 0.3549 - val_loss: 0.6663 - val_categorical_accuracy: 0.2523\n",
            "Epoch 137/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0375 - categorical_accuracy: 0.3552 - val_loss: 0.6712 - val_categorical_accuracy: 0.2524\n",
            "Epoch 138/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0368 - categorical_accuracy: 0.3554 - val_loss: 0.6665 - val_categorical_accuracy: 0.2524\n",
            "Epoch 139/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0366 - categorical_accuracy: 0.3554 - val_loss: 0.6709 - val_categorical_accuracy: 0.2523\n",
            "Epoch 140/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0359 - categorical_accuracy: 0.3555 - val_loss: 0.6730 - val_categorical_accuracy: 0.2525\n",
            "Epoch 141/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0355 - categorical_accuracy: 0.3557 - val_loss: 0.6718 - val_categorical_accuracy: 0.2526\n",
            "Epoch 142/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0350 - categorical_accuracy: 0.3559 - val_loss: 0.6785 - val_categorical_accuracy: 0.2518\n",
            "Epoch 143/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0349 - categorical_accuracy: 0.3561 - val_loss: 0.6760 - val_categorical_accuracy: 0.2524\n",
            "Epoch 144/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0346 - categorical_accuracy: 0.3560 - val_loss: 0.6824 - val_categorical_accuracy: 0.2515\n",
            "Epoch 145/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0342 - categorical_accuracy: 0.3561 - val_loss: 0.6804 - val_categorical_accuracy: 0.2526\n",
            "Epoch 146/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0336 - categorical_accuracy: 0.3564 - val_loss: 0.6800 - val_categorical_accuracy: 0.2522\n",
            "Epoch 147/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0336 - categorical_accuracy: 0.3562 - val_loss: 0.6817 - val_categorical_accuracy: 0.2528\n",
            "Epoch 148/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0330 - categorical_accuracy: 0.3566 - val_loss: 0.6931 - val_categorical_accuracy: 0.2520\n",
            "Epoch 149/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0331 - categorical_accuracy: 0.3564 - val_loss: 0.6868 - val_categorical_accuracy: 0.2521\n",
            "Epoch 150/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0327 - categorical_accuracy: 0.3568 - val_loss: 0.6873 - val_categorical_accuracy: 0.2525\n",
            "Epoch 151/500\n",
            "7999/7999 [==============================] - 11s 1ms/step - loss: 0.0323 - categorical_accuracy: 0.3568 - val_loss: 0.6898 - val_categorical_accuracy: 0.2522\n",
            "Epoch 152/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0320 - categorical_accuracy: 0.3568 - val_loss: 0.6919 - val_categorical_accuracy: 0.2522\n",
            "Epoch 153/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0318 - categorical_accuracy: 0.3567 - val_loss: 0.6952 - val_categorical_accuracy: 0.2517\n",
            "Epoch 154/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0315 - categorical_accuracy: 0.3570 - val_loss: 0.6935 - val_categorical_accuracy: 0.2523\n",
            "Epoch 155/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0313 - categorical_accuracy: 0.3569 - val_loss: 0.6942 - val_categorical_accuracy: 0.2523\n",
            "Epoch 156/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0311 - categorical_accuracy: 0.3571 - val_loss: 0.6982 - val_categorical_accuracy: 0.2522\n",
            "Epoch 157/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0308 - categorical_accuracy: 0.3571 - val_loss: 0.6980 - val_categorical_accuracy: 0.2529\n",
            "Epoch 158/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0309 - categorical_accuracy: 0.3571 - val_loss: 0.7014 - val_categorical_accuracy: 0.2518\n",
            "Epoch 159/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0304 - categorical_accuracy: 0.3573 - val_loss: 0.6988 - val_categorical_accuracy: 0.2531\n",
            "Epoch 160/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0304 - categorical_accuracy: 0.3573 - val_loss: 0.7011 - val_categorical_accuracy: 0.2522\n",
            "Epoch 161/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0303 - categorical_accuracy: 0.3572 - val_loss: 0.7048 - val_categorical_accuracy: 0.2520\n",
            "Epoch 162/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0297 - categorical_accuracy: 0.3574 - val_loss: 0.7041 - val_categorical_accuracy: 0.2530\n",
            "Epoch 163/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0295 - categorical_accuracy: 0.3576 - val_loss: 0.7056 - val_categorical_accuracy: 0.2526\n",
            "Epoch 164/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0301 - categorical_accuracy: 0.3572 - val_loss: 0.7054 - val_categorical_accuracy: 0.2525\n",
            "Epoch 165/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0293 - categorical_accuracy: 0.3575 - val_loss: 0.7071 - val_categorical_accuracy: 0.2527\n",
            "Epoch 166/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0292 - categorical_accuracy: 0.3575 - val_loss: 0.7088 - val_categorical_accuracy: 0.2527\n",
            "Epoch 167/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0289 - categorical_accuracy: 0.3577 - val_loss: 0.7047 - val_categorical_accuracy: 0.2535\n",
            "Epoch 168/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0286 - categorical_accuracy: 0.3578 - val_loss: 0.7120 - val_categorical_accuracy: 0.2526\n",
            "Epoch 169/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0284 - categorical_accuracy: 0.3578 - val_loss: 0.7214 - val_categorical_accuracy: 0.2517\n",
            "Epoch 170/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0283 - categorical_accuracy: 0.3577 - val_loss: 0.7151 - val_categorical_accuracy: 0.2523\n",
            "Epoch 171/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0283 - categorical_accuracy: 0.3578 - val_loss: 0.7155 - val_categorical_accuracy: 0.2519\n",
            "Epoch 172/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0285 - categorical_accuracy: 0.3577 - val_loss: 0.7132 - val_categorical_accuracy: 0.2523\n",
            "Epoch 173/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0282 - categorical_accuracy: 0.3579 - val_loss: 0.7163 - val_categorical_accuracy: 0.2522\n",
            "Epoch 174/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0281 - categorical_accuracy: 0.3577 - val_loss: 0.7183 - val_categorical_accuracy: 0.2521\n",
            "Epoch 175/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0279 - categorical_accuracy: 0.3578 - val_loss: 0.7199 - val_categorical_accuracy: 0.2522\n",
            "Epoch 176/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0275 - categorical_accuracy: 0.3581 - val_loss: 0.7185 - val_categorical_accuracy: 0.2517\n",
            "Epoch 177/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0274 - categorical_accuracy: 0.3581 - val_loss: 0.7219 - val_categorical_accuracy: 0.2524\n",
            "Epoch 178/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0273 - categorical_accuracy: 0.3581 - val_loss: 0.7176 - val_categorical_accuracy: 0.2519\n",
            "Epoch 179/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0273 - categorical_accuracy: 0.3580 - val_loss: 0.7227 - val_categorical_accuracy: 0.2527\n",
            "Epoch 180/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0271 - categorical_accuracy: 0.3581 - val_loss: 0.7195 - val_categorical_accuracy: 0.2528\n",
            "Epoch 181/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0269 - categorical_accuracy: 0.3582 - val_loss: 0.7218 - val_categorical_accuracy: 0.2535\n",
            "Epoch 182/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0269 - categorical_accuracy: 0.3582 - val_loss: 0.7263 - val_categorical_accuracy: 0.2527\n",
            "Epoch 183/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0269 - categorical_accuracy: 0.3581 - val_loss: 0.7282 - val_categorical_accuracy: 0.2523\n",
            "Epoch 184/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0266 - categorical_accuracy: 0.3584 - val_loss: 0.7276 - val_categorical_accuracy: 0.2529\n",
            "Epoch 185/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0261 - categorical_accuracy: 0.3585 - val_loss: 0.7303 - val_categorical_accuracy: 0.2521\n",
            "Epoch 186/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0264 - categorical_accuracy: 0.3584 - val_loss: 0.7318 - val_categorical_accuracy: 0.2518\n",
            "Epoch 187/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0258 - categorical_accuracy: 0.3585 - val_loss: 0.7295 - val_categorical_accuracy: 0.2535\n",
            "Epoch 188/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0258 - categorical_accuracy: 0.3585 - val_loss: 0.7330 - val_categorical_accuracy: 0.2524\n",
            "Epoch 189/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0260 - categorical_accuracy: 0.3584 - val_loss: 0.7342 - val_categorical_accuracy: 0.2534\n",
            "Epoch 190/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0262 - categorical_accuracy: 0.3583 - val_loss: 0.7334 - val_categorical_accuracy: 0.2525\n",
            "Epoch 191/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0258 - categorical_accuracy: 0.3583 - val_loss: 0.7380 - val_categorical_accuracy: 0.2525\n",
            "Epoch 192/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0257 - categorical_accuracy: 0.3585 - val_loss: 0.7306 - val_categorical_accuracy: 0.2529\n",
            "Epoch 193/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0258 - categorical_accuracy: 0.3584 - val_loss: 0.7321 - val_categorical_accuracy: 0.2530\n",
            "Epoch 194/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0257 - categorical_accuracy: 0.3585 - val_loss: 0.7356 - val_categorical_accuracy: 0.2527\n",
            "Epoch 195/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0253 - categorical_accuracy: 0.3586 - val_loss: 0.7336 - val_categorical_accuracy: 0.2537\n",
            "Epoch 196/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0255 - categorical_accuracy: 0.3584 - val_loss: 0.7349 - val_categorical_accuracy: 0.2529\n",
            "Epoch 197/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0251 - categorical_accuracy: 0.3586 - val_loss: 0.7352 - val_categorical_accuracy: 0.2522\n",
            "Epoch 198/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0252 - categorical_accuracy: 0.3586 - val_loss: 0.7422 - val_categorical_accuracy: 0.2524\n",
            "Epoch 199/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0252 - categorical_accuracy: 0.3586 - val_loss: 0.7383 - val_categorical_accuracy: 0.2527\n",
            "Epoch 200/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0246 - categorical_accuracy: 0.3588 - val_loss: 0.7371 - val_categorical_accuracy: 0.2531\n",
            "Epoch 201/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0249 - categorical_accuracy: 0.3587 - val_loss: 0.7390 - val_categorical_accuracy: 0.2527\n",
            "Epoch 202/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0250 - categorical_accuracy: 0.3586 - val_loss: 0.7431 - val_categorical_accuracy: 0.2524\n",
            "Epoch 203/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0247 - categorical_accuracy: 0.3585 - val_loss: 0.7433 - val_categorical_accuracy: 0.2527\n",
            "Epoch 204/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0246 - categorical_accuracy: 0.3587 - val_loss: 0.7417 - val_categorical_accuracy: 0.2523\n",
            "Epoch 205/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0244 - categorical_accuracy: 0.3587 - val_loss: 0.7399 - val_categorical_accuracy: 0.2522\n",
            "Epoch 206/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0244 - categorical_accuracy: 0.3588 - val_loss: 0.7417 - val_categorical_accuracy: 0.2528\n",
            "Epoch 207/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0246 - categorical_accuracy: 0.3587 - val_loss: 0.7423 - val_categorical_accuracy: 0.2532\n",
            "Epoch 208/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0245 - categorical_accuracy: 0.3587 - val_loss: 0.7446 - val_categorical_accuracy: 0.2526\n",
            "Epoch 209/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0246 - categorical_accuracy: 0.3586 - val_loss: 0.7456 - val_categorical_accuracy: 0.2527\n",
            "Epoch 210/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0242 - categorical_accuracy: 0.3588 - val_loss: 0.7472 - val_categorical_accuracy: 0.2517\n",
            "Epoch 211/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0239 - categorical_accuracy: 0.3588 - val_loss: 0.7461 - val_categorical_accuracy: 0.2521\n",
            "Epoch 212/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0241 - categorical_accuracy: 0.3588 - val_loss: 0.7456 - val_categorical_accuracy: 0.2526\n",
            "Epoch 213/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0240 - categorical_accuracy: 0.3589 - val_loss: 0.7571 - val_categorical_accuracy: 0.2513\n",
            "Epoch 214/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0241 - categorical_accuracy: 0.3588 - val_loss: 0.7494 - val_categorical_accuracy: 0.2531\n",
            "Epoch 215/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0239 - categorical_accuracy: 0.3587 - val_loss: 0.7486 - val_categorical_accuracy: 0.2523\n",
            "Epoch 216/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0241 - categorical_accuracy: 0.3588 - val_loss: 0.7489 - val_categorical_accuracy: 0.2527\n",
            "Epoch 217/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0240 - categorical_accuracy: 0.3588 - val_loss: 0.7461 - val_categorical_accuracy: 0.2523\n",
            "Epoch 218/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0234 - categorical_accuracy: 0.3590 - val_loss: 0.7495 - val_categorical_accuracy: 0.2522\n",
            "Epoch 219/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0238 - categorical_accuracy: 0.3589 - val_loss: 0.7493 - val_categorical_accuracy: 0.2524\n",
            "Epoch 220/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0235 - categorical_accuracy: 0.3589 - val_loss: 0.7537 - val_categorical_accuracy: 0.2530\n",
            "Epoch 221/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0240 - categorical_accuracy: 0.3587 - val_loss: 0.7485 - val_categorical_accuracy: 0.2526\n",
            "Epoch 222/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0233 - categorical_accuracy: 0.3588 - val_loss: 0.7594 - val_categorical_accuracy: 0.2518\n",
            "Epoch 223/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0234 - categorical_accuracy: 0.3589 - val_loss: 0.7602 - val_categorical_accuracy: 0.2525\n",
            "Epoch 224/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0237 - categorical_accuracy: 0.3588 - val_loss: 0.7557 - val_categorical_accuracy: 0.2533\n",
            "Epoch 225/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0236 - categorical_accuracy: 0.3589 - val_loss: 0.7537 - val_categorical_accuracy: 0.2530\n",
            "Epoch 226/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0233 - categorical_accuracy: 0.3590 - val_loss: 0.7605 - val_categorical_accuracy: 0.2524\n",
            "Epoch 227/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0231 - categorical_accuracy: 0.3591 - val_loss: 0.7577 - val_categorical_accuracy: 0.2528\n",
            "Epoch 228/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0234 - categorical_accuracy: 0.3588 - val_loss: 0.7563 - val_categorical_accuracy: 0.2526\n",
            "Epoch 229/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0233 - categorical_accuracy: 0.3589 - val_loss: 0.7581 - val_categorical_accuracy: 0.2531\n",
            "Epoch 230/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0230 - categorical_accuracy: 0.3591 - val_loss: 0.7556 - val_categorical_accuracy: 0.2528\n",
            "Epoch 231/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0232 - categorical_accuracy: 0.3590 - val_loss: 0.7552 - val_categorical_accuracy: 0.2529\n",
            "Epoch 232/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0229 - categorical_accuracy: 0.3591 - val_loss: 0.7540 - val_categorical_accuracy: 0.2531\n",
            "Epoch 233/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0229 - categorical_accuracy: 0.3591 - val_loss: 0.7568 - val_categorical_accuracy: 0.2537\n",
            "Epoch 234/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0233 - categorical_accuracy: 0.3587 - val_loss: 0.7550 - val_categorical_accuracy: 0.2531\n",
            "Epoch 235/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0229 - categorical_accuracy: 0.3590 - val_loss: 0.7584 - val_categorical_accuracy: 0.2524\n",
            "Epoch 236/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0232 - categorical_accuracy: 0.3588 - val_loss: 0.7562 - val_categorical_accuracy: 0.2531\n",
            "Epoch 237/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0229 - categorical_accuracy: 0.3592 - val_loss: 0.7561 - val_categorical_accuracy: 0.2535\n",
            "Epoch 238/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0227 - categorical_accuracy: 0.3590 - val_loss: 0.7590 - val_categorical_accuracy: 0.2528\n",
            "Epoch 239/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0227 - categorical_accuracy: 0.3592 - val_loss: 0.7552 - val_categorical_accuracy: 0.2530\n",
            "Epoch 240/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0224 - categorical_accuracy: 0.3593 - val_loss: 0.7581 - val_categorical_accuracy: 0.2532\n",
            "Epoch 241/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0227 - categorical_accuracy: 0.3590 - val_loss: 0.7603 - val_categorical_accuracy: 0.2530\n",
            "Epoch 242/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0225 - categorical_accuracy: 0.3592 - val_loss: 0.7611 - val_categorical_accuracy: 0.2526\n",
            "Epoch 243/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0223 - categorical_accuracy: 0.3592 - val_loss: 0.7670 - val_categorical_accuracy: 0.2531\n",
            "Epoch 244/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0226 - categorical_accuracy: 0.3590 - val_loss: 0.7602 - val_categorical_accuracy: 0.2528\n",
            "Epoch 245/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0223 - categorical_accuracy: 0.3592 - val_loss: 0.7620 - val_categorical_accuracy: 0.2531\n",
            "Epoch 246/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0225 - categorical_accuracy: 0.3591 - val_loss: 0.7641 - val_categorical_accuracy: 0.2528\n",
            "Epoch 247/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0224 - categorical_accuracy: 0.3591 - val_loss: 0.7631 - val_categorical_accuracy: 0.2532\n",
            "Epoch 248/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0224 - categorical_accuracy: 0.3589 - val_loss: 0.7609 - val_categorical_accuracy: 0.2526\n",
            "Epoch 249/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0221 - categorical_accuracy: 0.3591 - val_loss: 0.7682 - val_categorical_accuracy: 0.2518\n",
            "Epoch 250/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0221 - categorical_accuracy: 0.3594 - val_loss: 0.7648 - val_categorical_accuracy: 0.2526\n",
            "Epoch 251/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0227 - categorical_accuracy: 0.3589 - val_loss: 0.7639 - val_categorical_accuracy: 0.2524\n",
            "Epoch 252/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0224 - categorical_accuracy: 0.3591 - val_loss: 0.7665 - val_categorical_accuracy: 0.2526\n",
            "Epoch 253/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0220 - categorical_accuracy: 0.3592 - val_loss: 0.7686 - val_categorical_accuracy: 0.2529\n",
            "Epoch 254/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0221 - categorical_accuracy: 0.3593 - val_loss: 0.7679 - val_categorical_accuracy: 0.2529\n",
            "Epoch 255/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0221 - categorical_accuracy: 0.3591 - val_loss: 0.7707 - val_categorical_accuracy: 0.2527\n",
            "Epoch 256/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0221 - categorical_accuracy: 0.3592 - val_loss: 0.7719 - val_categorical_accuracy: 0.2517\n",
            "Epoch 257/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0224 - categorical_accuracy: 0.3590 - val_loss: 0.7695 - val_categorical_accuracy: 0.2530\n",
            "Epoch 258/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0220 - categorical_accuracy: 0.3592 - val_loss: 0.7650 - val_categorical_accuracy: 0.2527\n",
            "Epoch 259/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0220 - categorical_accuracy: 0.3593 - val_loss: 0.7677 - val_categorical_accuracy: 0.2525\n",
            "Epoch 260/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0216 - categorical_accuracy: 0.3593 - val_loss: 0.7711 - val_categorical_accuracy: 0.2528\n",
            "Epoch 261/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0219 - categorical_accuracy: 0.3592 - val_loss: 0.7656 - val_categorical_accuracy: 0.2533\n",
            "Epoch 262/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0217 - categorical_accuracy: 0.3593 - val_loss: 0.7663 - val_categorical_accuracy: 0.2530\n",
            "Epoch 263/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0216 - categorical_accuracy: 0.3593 - val_loss: 0.7700 - val_categorical_accuracy: 0.2527\n",
            "Epoch 264/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0217 - categorical_accuracy: 0.3594 - val_loss: 0.7744 - val_categorical_accuracy: 0.2522\n",
            "Epoch 265/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0217 - categorical_accuracy: 0.3591 - val_loss: 0.7656 - val_categorical_accuracy: 0.2527\n",
            "Epoch 266/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0219 - categorical_accuracy: 0.3593 - val_loss: 0.7689 - val_categorical_accuracy: 0.2533\n",
            "Epoch 267/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0214 - categorical_accuracy: 0.3594 - val_loss: 0.7696 - val_categorical_accuracy: 0.2535\n",
            "Epoch 268/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0215 - categorical_accuracy: 0.3592 - val_loss: 0.7703 - val_categorical_accuracy: 0.2527\n",
            "Epoch 269/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0215 - categorical_accuracy: 0.3594 - val_loss: 0.7729 - val_categorical_accuracy: 0.2527\n",
            "Epoch 270/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0213 - categorical_accuracy: 0.3593 - val_loss: 0.7680 - val_categorical_accuracy: 0.2523\n",
            "Epoch 271/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0216 - categorical_accuracy: 0.3593 - val_loss: 0.7702 - val_categorical_accuracy: 0.2524\n",
            "Epoch 272/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0214 - categorical_accuracy: 0.3592 - val_loss: 0.7707 - val_categorical_accuracy: 0.2530\n",
            "Epoch 273/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0214 - categorical_accuracy: 0.3595 - val_loss: 0.7726 - val_categorical_accuracy: 0.2527\n",
            "Epoch 274/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0215 - categorical_accuracy: 0.3593 - val_loss: 0.7746 - val_categorical_accuracy: 0.2532\n",
            "Epoch 275/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0214 - categorical_accuracy: 0.3593 - val_loss: 0.7722 - val_categorical_accuracy: 0.2529\n",
            "Epoch 276/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0213 - categorical_accuracy: 0.3594 - val_loss: 0.7732 - val_categorical_accuracy: 0.2533\n",
            "Epoch 277/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0213 - categorical_accuracy: 0.3594 - val_loss: 0.7682 - val_categorical_accuracy: 0.2534\n",
            "Epoch 278/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0212 - categorical_accuracy: 0.3593 - val_loss: 0.7734 - val_categorical_accuracy: 0.2529\n",
            "Epoch 279/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0210 - categorical_accuracy: 0.3593 - val_loss: 0.7725 - val_categorical_accuracy: 0.2529\n",
            "Epoch 280/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0214 - categorical_accuracy: 0.3594 - val_loss: 0.7711 - val_categorical_accuracy: 0.2538\n",
            "Epoch 281/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0209 - categorical_accuracy: 0.3594 - val_loss: 0.7714 - val_categorical_accuracy: 0.2525\n",
            "Epoch 282/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0211 - categorical_accuracy: 0.3593 - val_loss: 0.7779 - val_categorical_accuracy: 0.2525\n",
            "Epoch 283/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0211 - categorical_accuracy: 0.3592 - val_loss: 0.7755 - val_categorical_accuracy: 0.2527\n",
            "Epoch 284/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0207 - categorical_accuracy: 0.3593 - val_loss: 0.7762 - val_categorical_accuracy: 0.2533\n",
            "Epoch 285/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0213 - categorical_accuracy: 0.3592 - val_loss: 0.7741 - val_categorical_accuracy: 0.2531\n",
            "Epoch 286/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0210 - categorical_accuracy: 0.3594 - val_loss: 0.7721 - val_categorical_accuracy: 0.2533\n",
            "Epoch 287/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0211 - categorical_accuracy: 0.3593 - val_loss: 0.7721 - val_categorical_accuracy: 0.2540\n",
            "Epoch 288/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0213 - categorical_accuracy: 0.3593 - val_loss: 0.7768 - val_categorical_accuracy: 0.2526\n",
            "Epoch 289/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0210 - categorical_accuracy: 0.3593 - val_loss: 0.7732 - val_categorical_accuracy: 0.2534\n",
            "Epoch 290/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0207 - categorical_accuracy: 0.3595 - val_loss: 0.7703 - val_categorical_accuracy: 0.2533\n",
            "Epoch 291/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0210 - categorical_accuracy: 0.3593 - val_loss: 0.7755 - val_categorical_accuracy: 0.2535\n",
            "Epoch 292/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0209 - categorical_accuracy: 0.3594 - val_loss: 0.7779 - val_categorical_accuracy: 0.2534\n",
            "Epoch 293/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0211 - categorical_accuracy: 0.3594 - val_loss: 0.7766 - val_categorical_accuracy: 0.2534\n",
            "Epoch 294/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0204 - categorical_accuracy: 0.3595 - val_loss: 0.7721 - val_categorical_accuracy: 0.2535\n",
            "Epoch 295/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0210 - categorical_accuracy: 0.3592 - val_loss: 0.7768 - val_categorical_accuracy: 0.2537\n",
            "Epoch 296/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0208 - categorical_accuracy: 0.3593 - val_loss: 0.7725 - val_categorical_accuracy: 0.2538\n",
            "Epoch 297/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0208 - categorical_accuracy: 0.3595 - val_loss: 0.7766 - val_categorical_accuracy: 0.2531\n",
            "Epoch 298/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0205 - categorical_accuracy: 0.3594 - val_loss: 0.7749 - val_categorical_accuracy: 0.2532\n",
            "Epoch 299/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0206 - categorical_accuracy: 0.3595 - val_loss: 0.7779 - val_categorical_accuracy: 0.2528\n",
            "Epoch 300/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0206 - categorical_accuracy: 0.3594 - val_loss: 0.7812 - val_categorical_accuracy: 0.2524\n",
            "Epoch 301/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0206 - categorical_accuracy: 0.3594 - val_loss: 0.7733 - val_categorical_accuracy: 0.2537\n",
            "Epoch 302/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0207 - categorical_accuracy: 0.3594 - val_loss: 0.7712 - val_categorical_accuracy: 0.2531\n",
            "Epoch 303/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0208 - categorical_accuracy: 0.3593 - val_loss: 0.7766 - val_categorical_accuracy: 0.2534\n",
            "Epoch 304/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0207 - categorical_accuracy: 0.3593 - val_loss: 0.7756 - val_categorical_accuracy: 0.2533\n",
            "Epoch 305/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0204 - categorical_accuracy: 0.3595 - val_loss: 0.7754 - val_categorical_accuracy: 0.2529\n",
            "Epoch 306/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0204 - categorical_accuracy: 0.3595 - val_loss: 0.7825 - val_categorical_accuracy: 0.2532\n",
            "Epoch 307/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0206 - categorical_accuracy: 0.3594 - val_loss: 0.7758 - val_categorical_accuracy: 0.2535\n",
            "Epoch 308/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0208 - categorical_accuracy: 0.3595 - val_loss: 0.7748 - val_categorical_accuracy: 0.2533\n",
            "Epoch 309/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0201 - categorical_accuracy: 0.3596 - val_loss: 0.7739 - val_categorical_accuracy: 0.2536\n",
            "Epoch 310/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0204 - categorical_accuracy: 0.3595 - val_loss: 0.7831 - val_categorical_accuracy: 0.2531\n",
            "Epoch 311/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0201 - categorical_accuracy: 0.3595 - val_loss: 0.7801 - val_categorical_accuracy: 0.2530\n",
            "Epoch 312/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0204 - categorical_accuracy: 0.3595 - val_loss: 0.7840 - val_categorical_accuracy: 0.2531\n",
            "Epoch 313/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0203 - categorical_accuracy: 0.3595 - val_loss: 0.7803 - val_categorical_accuracy: 0.2532\n",
            "Epoch 314/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0201 - categorical_accuracy: 0.3596 - val_loss: 0.7795 - val_categorical_accuracy: 0.2531\n",
            "Epoch 315/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0204 - categorical_accuracy: 0.3596 - val_loss: 0.7781 - val_categorical_accuracy: 0.2529\n",
            "Epoch 316/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0203 - categorical_accuracy: 0.3595 - val_loss: 0.7746 - val_categorical_accuracy: 0.2532\n",
            "Epoch 317/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0202 - categorical_accuracy: 0.3595 - val_loss: 0.7817 - val_categorical_accuracy: 0.2535\n",
            "Epoch 318/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0203 - categorical_accuracy: 0.3596 - val_loss: 0.7784 - val_categorical_accuracy: 0.2533\n",
            "Epoch 319/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0200 - categorical_accuracy: 0.3596 - val_loss: 0.7788 - val_categorical_accuracy: 0.2535\n",
            "Epoch 320/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0202 - categorical_accuracy: 0.3594 - val_loss: 0.7824 - val_categorical_accuracy: 0.2529\n",
            "Epoch 321/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0201 - categorical_accuracy: 0.3595 - val_loss: 0.7807 - val_categorical_accuracy: 0.2537\n",
            "Epoch 322/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0201 - categorical_accuracy: 0.3596 - val_loss: 0.7825 - val_categorical_accuracy: 0.2531\n",
            "Epoch 323/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0200 - categorical_accuracy: 0.3595 - val_loss: 0.7773 - val_categorical_accuracy: 0.2539\n",
            "Epoch 324/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0200 - categorical_accuracy: 0.3596 - val_loss: 0.7880 - val_categorical_accuracy: 0.2526\n",
            "Epoch 325/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0198 - categorical_accuracy: 0.3596 - val_loss: 0.7808 - val_categorical_accuracy: 0.2526\n",
            "Epoch 326/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0198 - categorical_accuracy: 0.3596 - val_loss: 0.7780 - val_categorical_accuracy: 0.2541\n",
            "Epoch 327/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0200 - categorical_accuracy: 0.3595 - val_loss: 0.7759 - val_categorical_accuracy: 0.2532\n",
            "Epoch 328/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0198 - categorical_accuracy: 0.3594 - val_loss: 0.7776 - val_categorical_accuracy: 0.2534\n",
            "Epoch 329/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0198 - categorical_accuracy: 0.3596 - val_loss: 0.7899 - val_categorical_accuracy: 0.2530\n",
            "Epoch 330/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0198 - categorical_accuracy: 0.3596 - val_loss: 0.7883 - val_categorical_accuracy: 0.2528\n",
            "Epoch 331/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0199 - categorical_accuracy: 0.3596 - val_loss: 0.7821 - val_categorical_accuracy: 0.2534\n",
            "Epoch 332/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0195 - categorical_accuracy: 0.3598 - val_loss: 0.7843 - val_categorical_accuracy: 0.2530\n",
            "Epoch 333/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0198 - categorical_accuracy: 0.3597 - val_loss: 0.7847 - val_categorical_accuracy: 0.2523\n",
            "Epoch 334/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0198 - categorical_accuracy: 0.3595 - val_loss: 0.7826 - val_categorical_accuracy: 0.2540\n",
            "Epoch 335/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0197 - categorical_accuracy: 0.3596 - val_loss: 0.7834 - val_categorical_accuracy: 0.2532\n",
            "Epoch 336/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0198 - categorical_accuracy: 0.3595 - val_loss: 0.7833 - val_categorical_accuracy: 0.2525\n",
            "Epoch 337/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0196 - categorical_accuracy: 0.3596 - val_loss: 0.7864 - val_categorical_accuracy: 0.2534\n",
            "Epoch 338/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0197 - categorical_accuracy: 0.3596 - val_loss: 0.7838 - val_categorical_accuracy: 0.2534\n",
            "Epoch 339/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0198 - categorical_accuracy: 0.3595 - val_loss: 0.7818 - val_categorical_accuracy: 0.2535\n",
            "Epoch 340/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0194 - categorical_accuracy: 0.3597 - val_loss: 0.7833 - val_categorical_accuracy: 0.2531\n",
            "Epoch 341/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0197 - categorical_accuracy: 0.3596 - val_loss: 0.7900 - val_categorical_accuracy: 0.2523\n",
            "Epoch 342/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0195 - categorical_accuracy: 0.3595 - val_loss: 0.7797 - val_categorical_accuracy: 0.2535\n",
            "Epoch 343/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0195 - categorical_accuracy: 0.3595 - val_loss: 0.7858 - val_categorical_accuracy: 0.2537\n",
            "Epoch 344/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0196 - categorical_accuracy: 0.3597 - val_loss: 0.7844 - val_categorical_accuracy: 0.2532\n",
            "Epoch 345/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0194 - categorical_accuracy: 0.3598 - val_loss: 0.7880 - val_categorical_accuracy: 0.2531\n",
            "Epoch 346/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0195 - categorical_accuracy: 0.3597 - val_loss: 0.7849 - val_categorical_accuracy: 0.2531\n",
            "Epoch 347/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0197 - categorical_accuracy: 0.3595 - val_loss: 0.7945 - val_categorical_accuracy: 0.2525\n",
            "Epoch 348/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0196 - categorical_accuracy: 0.3596 - val_loss: 0.7868 - val_categorical_accuracy: 0.2536\n",
            "Epoch 349/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0194 - categorical_accuracy: 0.3596 - val_loss: 0.7805 - val_categorical_accuracy: 0.2536\n",
            "Epoch 350/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0196 - categorical_accuracy: 0.3594 - val_loss: 0.7856 - val_categorical_accuracy: 0.2534\n",
            "Epoch 351/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0197 - categorical_accuracy: 0.3596 - val_loss: 0.7839 - val_categorical_accuracy: 0.2542\n",
            "Epoch 352/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0194 - categorical_accuracy: 0.3596 - val_loss: 0.7882 - val_categorical_accuracy: 0.2539\n",
            "Epoch 353/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0193 - categorical_accuracy: 0.3596 - val_loss: 0.7876 - val_categorical_accuracy: 0.2532\n",
            "Epoch 354/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0192 - categorical_accuracy: 0.3596 - val_loss: 0.7854 - val_categorical_accuracy: 0.2528\n",
            "Epoch 355/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0193 - categorical_accuracy: 0.3596 - val_loss: 0.7896 - val_categorical_accuracy: 0.2534\n",
            "Epoch 356/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0192 - categorical_accuracy: 0.3598 - val_loss: 0.7812 - val_categorical_accuracy: 0.2530\n",
            "Epoch 357/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0195 - categorical_accuracy: 0.3596 - val_loss: 0.7863 - val_categorical_accuracy: 0.2532\n",
            "Epoch 358/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0194 - categorical_accuracy: 0.3596 - val_loss: 0.7880 - val_categorical_accuracy: 0.2538\n",
            "Epoch 359/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0191 - categorical_accuracy: 0.3597 - val_loss: 0.7823 - val_categorical_accuracy: 0.2540\n",
            "Epoch 360/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0196 - categorical_accuracy: 0.3595 - val_loss: 0.7823 - val_categorical_accuracy: 0.2540\n",
            "Epoch 361/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0190 - categorical_accuracy: 0.3597 - val_loss: 0.7851 - val_categorical_accuracy: 0.2536\n",
            "Epoch 362/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0193 - categorical_accuracy: 0.3595 - val_loss: 0.7875 - val_categorical_accuracy: 0.2530\n",
            "Epoch 363/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0192 - categorical_accuracy: 0.3597 - val_loss: 0.7854 - val_categorical_accuracy: 0.2531\n",
            "Epoch 364/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0189 - categorical_accuracy: 0.3597 - val_loss: 0.7858 - val_categorical_accuracy: 0.2533\n",
            "Epoch 365/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0195 - categorical_accuracy: 0.3597 - val_loss: 0.7838 - val_categorical_accuracy: 0.2531\n",
            "Epoch 366/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0190 - categorical_accuracy: 0.3597 - val_loss: 0.7834 - val_categorical_accuracy: 0.2535\n",
            "Epoch 367/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0191 - categorical_accuracy: 0.3597 - val_loss: 0.7899 - val_categorical_accuracy: 0.2535\n",
            "Epoch 368/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0191 - categorical_accuracy: 0.3597 - val_loss: 0.7876 - val_categorical_accuracy: 0.2534\n",
            "Epoch 369/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0194 - categorical_accuracy: 0.3596 - val_loss: 0.7869 - val_categorical_accuracy: 0.2532\n",
            "Epoch 370/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0190 - categorical_accuracy: 0.3596 - val_loss: 0.7883 - val_categorical_accuracy: 0.2532\n",
            "Epoch 371/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0191 - categorical_accuracy: 0.3596 - val_loss: 0.7807 - val_categorical_accuracy: 0.2534\n",
            "Epoch 372/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0189 - categorical_accuracy: 0.3596 - val_loss: 0.7837 - val_categorical_accuracy: 0.2530\n",
            "Epoch 373/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0189 - categorical_accuracy: 0.3597 - val_loss: 0.7865 - val_categorical_accuracy: 0.2538\n",
            "Epoch 374/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0190 - categorical_accuracy: 0.3597 - val_loss: 0.7849 - val_categorical_accuracy: 0.2533\n",
            "Epoch 375/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0189 - categorical_accuracy: 0.3598 - val_loss: 0.7902 - val_categorical_accuracy: 0.2530\n",
            "Epoch 376/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0191 - categorical_accuracy: 0.3596 - val_loss: 0.7834 - val_categorical_accuracy: 0.2537\n",
            "Epoch 377/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0189 - categorical_accuracy: 0.3597 - val_loss: 0.7938 - val_categorical_accuracy: 0.2536\n",
            "Epoch 378/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0188 - categorical_accuracy: 0.3599 - val_loss: 0.7830 - val_categorical_accuracy: 0.2534\n",
            "Epoch 379/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0192 - categorical_accuracy: 0.3596 - val_loss: 0.7857 - val_categorical_accuracy: 0.2529\n",
            "Epoch 380/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0190 - categorical_accuracy: 0.3596 - val_loss: 0.7874 - val_categorical_accuracy: 0.2528\n",
            "Epoch 381/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0192 - categorical_accuracy: 0.3596 - val_loss: 0.7877 - val_categorical_accuracy: 0.2535\n",
            "Epoch 382/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0189 - categorical_accuracy: 0.3596 - val_loss: 0.7893 - val_categorical_accuracy: 0.2530\n",
            "Epoch 383/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0189 - categorical_accuracy: 0.3597 - val_loss: 0.7854 - val_categorical_accuracy: 0.2536\n",
            "Epoch 384/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0191 - categorical_accuracy: 0.3597 - val_loss: 0.7888 - val_categorical_accuracy: 0.2537\n",
            "Epoch 385/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0186 - categorical_accuracy: 0.3598 - val_loss: 0.7867 - val_categorical_accuracy: 0.2535\n",
            "Epoch 386/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0191 - categorical_accuracy: 0.3597 - val_loss: 0.7830 - val_categorical_accuracy: 0.2541\n",
            "Epoch 387/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0189 - categorical_accuracy: 0.3597 - val_loss: 0.7831 - val_categorical_accuracy: 0.2537\n",
            "Epoch 388/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0188 - categorical_accuracy: 0.3597 - val_loss: 0.7855 - val_categorical_accuracy: 0.2535\n",
            "Epoch 389/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0187 - categorical_accuracy: 0.3597 - val_loss: 0.7886 - val_categorical_accuracy: 0.2533\n",
            "Epoch 390/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0187 - categorical_accuracy: 0.3596 - val_loss: 0.7858 - val_categorical_accuracy: 0.2541\n",
            "Epoch 391/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0189 - categorical_accuracy: 0.3596 - val_loss: 0.7852 - val_categorical_accuracy: 0.2537\n",
            "Epoch 392/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0188 - categorical_accuracy: 0.3597 - val_loss: 0.7871 - val_categorical_accuracy: 0.2534\n",
            "Epoch 393/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0188 - categorical_accuracy: 0.3597 - val_loss: 0.7926 - val_categorical_accuracy: 0.2531\n",
            "Epoch 394/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0188 - categorical_accuracy: 0.3597 - val_loss: 0.7865 - val_categorical_accuracy: 0.2531\n",
            "Epoch 395/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0190 - categorical_accuracy: 0.3598 - val_loss: 0.7862 - val_categorical_accuracy: 0.2530\n",
            "Epoch 396/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0187 - categorical_accuracy: 0.3598 - val_loss: 0.7855 - val_categorical_accuracy: 0.2535\n",
            "Epoch 397/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0188 - categorical_accuracy: 0.3596 - val_loss: 0.7851 - val_categorical_accuracy: 0.2542\n",
            "Epoch 398/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0186 - categorical_accuracy: 0.3599 - val_loss: 0.7871 - val_categorical_accuracy: 0.2535\n",
            "Epoch 399/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0188 - categorical_accuracy: 0.3596 - val_loss: 0.7888 - val_categorical_accuracy: 0.2534\n",
            "Epoch 400/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0186 - categorical_accuracy: 0.3597 - val_loss: 0.7906 - val_categorical_accuracy: 0.2532\n",
            "Epoch 401/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0184 - categorical_accuracy: 0.3597 - val_loss: 0.7864 - val_categorical_accuracy: 0.2535\n",
            "Epoch 402/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0186 - categorical_accuracy: 0.3597 - val_loss: 0.7878 - val_categorical_accuracy: 0.2533\n",
            "Epoch 403/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0186 - categorical_accuracy: 0.3598 - val_loss: 0.7906 - val_categorical_accuracy: 0.2536\n",
            "Epoch 404/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0185 - categorical_accuracy: 0.3597 - val_loss: 0.7878 - val_categorical_accuracy: 0.2529\n",
            "Epoch 405/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0186 - categorical_accuracy: 0.3597 - val_loss: 0.7894 - val_categorical_accuracy: 0.2538\n",
            "Epoch 406/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0188 - categorical_accuracy: 0.3596 - val_loss: 0.7899 - val_categorical_accuracy: 0.2533\n",
            "Epoch 407/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0187 - categorical_accuracy: 0.3596 - val_loss: 0.7909 - val_categorical_accuracy: 0.2540\n",
            "Epoch 408/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0183 - categorical_accuracy: 0.3598 - val_loss: 0.7932 - val_categorical_accuracy: 0.2533\n",
            "Epoch 409/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0189 - categorical_accuracy: 0.3597 - val_loss: 0.7921 - val_categorical_accuracy: 0.2543\n",
            "Epoch 410/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0184 - categorical_accuracy: 0.3598 - val_loss: 0.7938 - val_categorical_accuracy: 0.2525\n",
            "Epoch 411/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0186 - categorical_accuracy: 0.3597 - val_loss: 0.7937 - val_categorical_accuracy: 0.2532\n",
            "Epoch 412/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0185 - categorical_accuracy: 0.3597 - val_loss: 0.7884 - val_categorical_accuracy: 0.2543\n",
            "Epoch 413/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0183 - categorical_accuracy: 0.3598 - val_loss: 0.7859 - val_categorical_accuracy: 0.2539\n",
            "Epoch 414/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0183 - categorical_accuracy: 0.3598 - val_loss: 0.7866 - val_categorical_accuracy: 0.2541\n",
            "Epoch 415/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0184 - categorical_accuracy: 0.3598 - val_loss: 0.7933 - val_categorical_accuracy: 0.2530\n",
            "Epoch 416/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0184 - categorical_accuracy: 0.3597 - val_loss: 0.7909 - val_categorical_accuracy: 0.2536\n",
            "Epoch 417/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0184 - categorical_accuracy: 0.3597 - val_loss: 0.7914 - val_categorical_accuracy: 0.2537\n",
            "Epoch 418/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0186 - categorical_accuracy: 0.3595 - val_loss: 0.7932 - val_categorical_accuracy: 0.2532\n",
            "Epoch 419/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0185 - categorical_accuracy: 0.3597 - val_loss: 0.7967 - val_categorical_accuracy: 0.2538\n",
            "Epoch 420/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0185 - categorical_accuracy: 0.3597 - val_loss: 0.7965 - val_categorical_accuracy: 0.2536\n",
            "Epoch 421/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0184 - categorical_accuracy: 0.3596 - val_loss: 0.7902 - val_categorical_accuracy: 0.2539\n",
            "Epoch 422/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0183 - categorical_accuracy: 0.3597 - val_loss: 0.7967 - val_categorical_accuracy: 0.2535\n",
            "Epoch 423/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0182 - categorical_accuracy: 0.3598 - val_loss: 0.7968 - val_categorical_accuracy: 0.2537\n",
            "Epoch 424/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0184 - categorical_accuracy: 0.3597 - val_loss: 0.7891 - val_categorical_accuracy: 0.2538\n",
            "Epoch 425/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0184 - categorical_accuracy: 0.3597 - val_loss: 0.7916 - val_categorical_accuracy: 0.2538\n",
            "Epoch 426/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0183 - categorical_accuracy: 0.3598 - val_loss: 0.7918 - val_categorical_accuracy: 0.2535\n",
            "Epoch 427/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0182 - categorical_accuracy: 0.3596 - val_loss: 0.7893 - val_categorical_accuracy: 0.2542\n",
            "Epoch 428/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0181 - categorical_accuracy: 0.3598 - val_loss: 0.7893 - val_categorical_accuracy: 0.2543\n",
            "Epoch 429/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0183 - categorical_accuracy: 0.3597 - val_loss: 0.7917 - val_categorical_accuracy: 0.2537\n",
            "Epoch 430/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0183 - categorical_accuracy: 0.3597 - val_loss: 0.7931 - val_categorical_accuracy: 0.2534\n",
            "Epoch 431/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0185 - categorical_accuracy: 0.3597 - val_loss: 0.7938 - val_categorical_accuracy: 0.2534\n",
            "Epoch 432/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0182 - categorical_accuracy: 0.3597 - val_loss: 0.7979 - val_categorical_accuracy: 0.2534\n",
            "Epoch 433/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0181 - categorical_accuracy: 0.3598 - val_loss: 0.7957 - val_categorical_accuracy: 0.2532\n",
            "Epoch 434/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0182 - categorical_accuracy: 0.3597 - val_loss: 0.7906 - val_categorical_accuracy: 0.2536\n",
            "Epoch 435/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0184 - categorical_accuracy: 0.3598 - val_loss: 0.7927 - val_categorical_accuracy: 0.2534\n",
            "Epoch 436/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0183 - categorical_accuracy: 0.3598 - val_loss: 0.7965 - val_categorical_accuracy: 0.2534\n",
            "Epoch 437/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0183 - categorical_accuracy: 0.3598 - val_loss: 0.7947 - val_categorical_accuracy: 0.2534\n",
            "Epoch 438/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0183 - categorical_accuracy: 0.3596 - val_loss: 0.8024 - val_categorical_accuracy: 0.2529\n",
            "Epoch 439/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0183 - categorical_accuracy: 0.3597 - val_loss: 0.7936 - val_categorical_accuracy: 0.2542\n",
            "Epoch 440/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0181 - categorical_accuracy: 0.3597 - val_loss: 0.7903 - val_categorical_accuracy: 0.2536\n",
            "Epoch 441/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0183 - categorical_accuracy: 0.3597 - val_loss: 0.7906 - val_categorical_accuracy: 0.2532\n",
            "Epoch 442/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0182 - categorical_accuracy: 0.3598 - val_loss: 0.7974 - val_categorical_accuracy: 0.2533\n",
            "Epoch 443/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0182 - categorical_accuracy: 0.3598 - val_loss: 0.7961 - val_categorical_accuracy: 0.2538\n",
            "Epoch 444/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0180 - categorical_accuracy: 0.3598 - val_loss: 0.7919 - val_categorical_accuracy: 0.2531\n",
            "Epoch 445/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0181 - categorical_accuracy: 0.3599 - val_loss: 0.7902 - val_categorical_accuracy: 0.2535\n",
            "Epoch 446/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0181 - categorical_accuracy: 0.3597 - val_loss: 0.7875 - val_categorical_accuracy: 0.2539\n",
            "Epoch 447/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0181 - categorical_accuracy: 0.3596 - val_loss: 0.7922 - val_categorical_accuracy: 0.2534\n",
            "Epoch 448/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0179 - categorical_accuracy: 0.3598 - val_loss: 0.7919 - val_categorical_accuracy: 0.2531\n",
            "Epoch 449/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0183 - categorical_accuracy: 0.3597 - val_loss: 0.7931 - val_categorical_accuracy: 0.2532\n",
            "Epoch 450/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0181 - categorical_accuracy: 0.3597 - val_loss: 0.7946 - val_categorical_accuracy: 0.2529\n",
            "Epoch 451/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0179 - categorical_accuracy: 0.3599 - val_loss: 0.7917 - val_categorical_accuracy: 0.2534\n",
            "Epoch 452/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0182 - categorical_accuracy: 0.3599 - val_loss: 0.7881 - val_categorical_accuracy: 0.2542\n",
            "Epoch 453/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0181 - categorical_accuracy: 0.3598 - val_loss: 0.7950 - val_categorical_accuracy: 0.2531\n",
            "Epoch 454/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0181 - categorical_accuracy: 0.3599 - val_loss: 0.7935 - val_categorical_accuracy: 0.2529\n",
            "Epoch 455/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0181 - categorical_accuracy: 0.3598 - val_loss: 0.7932 - val_categorical_accuracy: 0.2533\n",
            "Epoch 456/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0181 - categorical_accuracy: 0.3597 - val_loss: 0.7966 - val_categorical_accuracy: 0.2526\n",
            "Epoch 457/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0182 - categorical_accuracy: 0.3598 - val_loss: 0.7956 - val_categorical_accuracy: 0.2534\n",
            "Epoch 458/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0181 - categorical_accuracy: 0.3599 - val_loss: 0.7962 - val_categorical_accuracy: 0.2537\n",
            "Epoch 459/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0178 - categorical_accuracy: 0.3598 - val_loss: 0.7987 - val_categorical_accuracy: 0.2533\n",
            "Epoch 460/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0181 - categorical_accuracy: 0.3597 - val_loss: 0.7919 - val_categorical_accuracy: 0.2537\n",
            "Epoch 461/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0180 - categorical_accuracy: 0.3597 - val_loss: 0.7939 - val_categorical_accuracy: 0.2534\n",
            "Epoch 462/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0178 - categorical_accuracy: 0.3599 - val_loss: 0.7900 - val_categorical_accuracy: 0.2531\n",
            "Epoch 463/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0178 - categorical_accuracy: 0.3599 - val_loss: 0.7912 - val_categorical_accuracy: 0.2535\n",
            "Epoch 464/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0179 - categorical_accuracy: 0.3599 - val_loss: 0.7879 - val_categorical_accuracy: 0.2539\n",
            "Epoch 465/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0179 - categorical_accuracy: 0.3598 - val_loss: 0.7935 - val_categorical_accuracy: 0.2535\n",
            "Epoch 466/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0176 - categorical_accuracy: 0.3599 - val_loss: 0.7927 - val_categorical_accuracy: 0.2536\n",
            "Epoch 467/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0179 - categorical_accuracy: 0.3598 - val_loss: 0.7967 - val_categorical_accuracy: 0.2534\n",
            "Epoch 468/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0176 - categorical_accuracy: 0.3600 - val_loss: 0.7927 - val_categorical_accuracy: 0.2538\n",
            "Epoch 469/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0180 - categorical_accuracy: 0.3597 - val_loss: 0.7887 - val_categorical_accuracy: 0.2541\n",
            "Epoch 470/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0179 - categorical_accuracy: 0.3597 - val_loss: 0.7948 - val_categorical_accuracy: 0.2540\n",
            "Epoch 471/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0179 - categorical_accuracy: 0.3597 - val_loss: 0.7942 - val_categorical_accuracy: 0.2535\n",
            "Epoch 472/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0177 - categorical_accuracy: 0.3599 - val_loss: 0.7892 - val_categorical_accuracy: 0.2539\n",
            "Epoch 473/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0177 - categorical_accuracy: 0.3598 - val_loss: 0.7924 - val_categorical_accuracy: 0.2540\n",
            "Epoch 474/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0177 - categorical_accuracy: 0.3599 - val_loss: 0.7951 - val_categorical_accuracy: 0.2538\n",
            "Epoch 475/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0178 - categorical_accuracy: 0.3598 - val_loss: 0.7952 - val_categorical_accuracy: 0.2531\n",
            "Epoch 476/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0179 - categorical_accuracy: 0.3596 - val_loss: 0.7925 - val_categorical_accuracy: 0.2541\n",
            "Epoch 477/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0176 - categorical_accuracy: 0.3597 - val_loss: 0.7918 - val_categorical_accuracy: 0.2534\n",
            "Epoch 478/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0177 - categorical_accuracy: 0.3598 - val_loss: 0.7945 - val_categorical_accuracy: 0.2539\n",
            "Epoch 479/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0178 - categorical_accuracy: 0.3598 - val_loss: 0.7976 - val_categorical_accuracy: 0.2535\n",
            "Epoch 480/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0178 - categorical_accuracy: 0.3598 - val_loss: 0.7937 - val_categorical_accuracy: 0.2540\n",
            "Epoch 481/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0178 - categorical_accuracy: 0.3597 - val_loss: 0.7943 - val_categorical_accuracy: 0.2542\n",
            "Epoch 482/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0177 - categorical_accuracy: 0.3598 - val_loss: 0.7968 - val_categorical_accuracy: 0.2535\n",
            "Epoch 483/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0176 - categorical_accuracy: 0.3598 - val_loss: 0.7923 - val_categorical_accuracy: 0.2536\n",
            "Epoch 484/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0176 - categorical_accuracy: 0.3598 - val_loss: 0.7952 - val_categorical_accuracy: 0.2535\n",
            "Epoch 485/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0175 - categorical_accuracy: 0.3598 - val_loss: 0.8011 - val_categorical_accuracy: 0.2536\n",
            "Epoch 486/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0177 - categorical_accuracy: 0.3598 - val_loss: 0.7993 - val_categorical_accuracy: 0.2532\n",
            "Epoch 487/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0176 - categorical_accuracy: 0.3598 - val_loss: 0.7941 - val_categorical_accuracy: 0.2539\n",
            "Epoch 488/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0175 - categorical_accuracy: 0.3599 - val_loss: 0.7936 - val_categorical_accuracy: 0.2543\n",
            "Epoch 489/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0178 - categorical_accuracy: 0.3598 - val_loss: 0.7921 - val_categorical_accuracy: 0.2538\n",
            "Epoch 490/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0177 - categorical_accuracy: 0.3599 - val_loss: 0.7914 - val_categorical_accuracy: 0.2539\n",
            "Epoch 491/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0175 - categorical_accuracy: 0.3598 - val_loss: 0.7944 - val_categorical_accuracy: 0.2529\n",
            "Epoch 492/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0177 - categorical_accuracy: 0.3597 - val_loss: 0.7940 - val_categorical_accuracy: 0.2539\n",
            "Epoch 493/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0175 - categorical_accuracy: 0.3599 - val_loss: 0.7924 - val_categorical_accuracy: 0.2540\n",
            "Epoch 494/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0176 - categorical_accuracy: 0.3599 - val_loss: 0.7951 - val_categorical_accuracy: 0.2535\n",
            "Epoch 495/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0175 - categorical_accuracy: 0.3599 - val_loss: 0.7973 - val_categorical_accuracy: 0.2532\n",
            "Epoch 496/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0175 - categorical_accuracy: 0.3599 - val_loss: 0.7982 - val_categorical_accuracy: 0.2534\n",
            "Epoch 497/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0174 - categorical_accuracy: 0.3599 - val_loss: 0.7979 - val_categorical_accuracy: 0.2539\n",
            "Epoch 498/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0175 - categorical_accuracy: 0.3598 - val_loss: 0.7946 - val_categorical_accuracy: 0.2539\n",
            "Epoch 499/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0175 - categorical_accuracy: 0.3598 - val_loss: 0.7937 - val_categorical_accuracy: 0.2542\n",
            "Epoch 500/500\n",
            "7999/7999 [==============================] - 10s 1ms/step - loss: 0.0176 - categorical_accuracy: 0.3599 - val_loss: 0.7944 - val_categorical_accuracy: 0.2538\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9fdbf0c278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o4khltlof6H",
        "colab_type": "text"
      },
      "source": [
        "### Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVgGMc5Lojmo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "69fa174d-d304-4779-8f27-76f631f79327"
      },
      "source": [
        "# Save model\n",
        "model.save('s2s.h5')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/network.py:877: UserWarning: Layer lstm_7 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_2/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_2/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
            "  '. They will not be included '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zbLdraJ1XpsR"
      },
      "source": [
        "## Run the below code for inferencing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4O7jtJYh29uo",
        "colab": {}
      },
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scaoVQVapHLk",
        "colab_type": "text"
      },
      "source": [
        "## Reverse-lookup token index to decode sequences back to something readable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_3t_ntoTq0fP",
        "colab": {}
      },
      "source": [
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict(\n",
        "    (i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict(\n",
        "    (i, char) for char, i in target_token_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9WAWX6ApcrG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "7390a0b1-2193-47d7-929d-43b6390505d7"
      },
      "source": [
        "print(reverse_input_char_index)\n",
        "print(reverse_target_char_index)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: ' ', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z'}\n",
            "{0: '\\t', 1: '\\n', 2: ' ', 3: 'a', 4: 'b', 5: 'c', 6: 'd', 7: 'e', 8: 'f', 9: 'g', 10: 'h', 11: 'i', 12: 'j', 13: 'k', 14: 'l', 15: 'm', 16: 'n', 17: 'o', 18: 'p', 19: 'q', 20: 'r', 21: 's', 22: 't', 23: 'u', 24: 'v', 25: 'w', 26: 'x', 27: 'y', 28: 'z'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FYJkd_AZq0iI",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_decoder_seq_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jiPl9MHkXv0z"
      },
      "source": [
        "## Run the below code for checking some outputs from the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7IFQIeCGq0nk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "outputId": "ea124687-93f2-4b36-c9b9-821d68d6870e"
      },
      "source": [
        "for seq_index in range(10):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print('-')\n",
        "    print('Input sentence:', input_texts[seq_index])\n",
        "    print('Decoded sentence:', decoded_sentence)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: stay with us\n",
            "Decoded sentence: bleib bei uns\n",
            "\n",
            "-\n",
            "Input sentence: she wants him\n",
            "Decoded sentence: sie will ihn\n",
            "\n",
            "-\n",
            "Input sentence: youre strong\n",
            "Decoded sentence: du bist stark\n",
            "\n",
            "-\n",
            "Input sentence: examine this\n",
            "Decoded sentence: untersuchen sie das\n",
            "\n",
            "-\n",
            "Input sentence: heres my card\n",
            "Decoded sentence: hier ist meine karte\n",
            "\n",
            "-\n",
            "Input sentence: tom burped\n",
            "Decoded sentence: tom rulpste\n",
            "\n",
            "-\n",
            "Input sentence: it is no joke\n",
            "Decoded sentence: das ist kein witz\n",
            "\n",
            "-\n",
            "Input sentence: tom is a spy\n",
            "Decoded sentence: tom ist ein spion\n",
            "\n",
            "-\n",
            "Input sentence: im a teenager\n",
            "Decoded sentence: ich bin ein teenager\n",
            "\n",
            "-\n",
            "Input sentence: im not crazy\n",
            "Decoded sentence: ich bin nicht verruckt\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRMqSt86JPiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}