{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "titan_dict={\"sales_person\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30],\n",
    "            \"old_scheme\" :[57,103,59,75,84,73,35,110,44,82,67,64,78,53,41,39,80,87,73,65,28,62,49,84,63,77,67,101,91,50],\n",
    "            \"new_scheme\":[62,122,54,82,84,86,32,104,38,107,84,85,99,39,34,58,73,53,66,78,41,71,38,95,81,58,75,94,100,68]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "titan_df=pd.DataFrame.from_dict(titan_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate mean of two schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "old_scheme    68.033333\n",
       "new_scheme    72.033333\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titan_df[[\"old_scheme\",\"new_scheme\"]].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis:\n",
    "\n",
    "\n",
    "Null Hypothesis: Both Old and New Schemes are almost same and not much different\n",
    "\n",
    "\n",
    "Alternate Hypothesis: New scheme has made significant difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the five percent significance test over the data to determine the p value to check new scheme has significantly raised outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-0.6937067608923764, pvalue=0.49063515686248105)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import shapiro\n",
    "stats.ttest_ind(titan_df['old_scheme'], titan_df['new_scheme'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pvalue = 0.49063515686248105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pvalue = 0.49063515686248105"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What conclusion does the test (p-value) lead to\n",
    "\n",
    "\n",
    "pvalue>level of significance(0.05)\n",
    "\n",
    "\n",
    "Fail to reject the NULL Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis:\n",
    "\n",
    "\n",
    "Null Hypothesis: Increasing the average output by 5000 doesn't give Titan a breakeven \n",
    "\n",
    "\n",
    "Alternate Hypothesis: Average output of the old scheme increased by 5000 gives Titan a breakeven (Mean of new scheme = old_scheme.mean()+5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability of type 1 error 0.09552108548116325"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t Test: Ttest_1sampResult(statistic=-1.338783455563436, pvalue=0.1910421709623265)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.09552108548116325"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probability of type 1 error\n",
    "\n",
    "\n",
    "pValue = stats.ttest_1samp(titan_df[\"old_scheme\"], titan_df[\"old_scheme\"].mean()+5)\n",
    "print(\"t Test:\", pValue)\n",
    "pValue=pValue.pvalue/2\n",
    "\n",
    "pValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the p- value of the hypothesis test if we test for a difference of 5000: 0.9044789145188368"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9044789145188368"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Real pValue for Hypothesis test is:\n",
    "\n",
    "real_pvalue=1-pValue\n",
    "real_pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d by the 1st method = -0.24442729940893634\n"
     ]
    }
   ],
   "source": [
    "from numpy import std, mean, sqrt\n",
    "\n",
    "#correct if the population S.D. is expected to be equal for the two groups.\n",
    "def cohen_d(x,y):\n",
    "    nx = len(x)\n",
    "    ny = len(y)\n",
    "    dof = nx + ny - 2\n",
    "    return (mean(x) - mean(y)) / sqrt(((nx-1)*std(x, ddof=1) ** 2 + (ny-1)*std(y, ddof=1) ** 2) / dof)\n",
    "\n",
    "# data\n",
    "x = titan_df[\"old_scheme\"]\n",
    "y = [i+5 for i in x]\n",
    "\n",
    "\n",
    "#correct only if nx=ny\n",
    "d = (mean(x) - mean(y)) / sqrt((std(x, ddof=1) ** 2 + std(y, ddof=1) ** 2) / 2.0)\n",
    "print (\"d by the 1st method = \" + str(d))\n",
    "if (len(x) != len(y)):\n",
    "    print(\"The first method is incorrect because nx is not equal to ny.\")\n",
    "\n",
    "#correct for more general case including nx !=ny\n",
    "#print (\"d by the more general 2nd method = \" + str(cohen_d(x,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_effect_size=cohen_d(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Power of the test: 0.236826543574698"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required power: 0.24\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.power import TTestIndPower\n",
    "# parameters for the analysis \n",
    "effect_size = act_effect_size#-0.24\n",
    "alpha = pValue # significance level\n",
    "\n",
    "sample= 30\n",
    "\n",
    "power_analysis = TTestIndPower()\n",
    "power = power_analysis.solve_power(effect_size = effect_size, \n",
    "                                         nobs1 = sample, \n",
    "                                         alpha = alpha)\n",
    "\n",
    "print('Required power: {0:.2f}'.format(power))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.236826543574698"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
