{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FU-HwvIdH0M-"
   },
   "source": [
    "## Sentiment analysis <br> \n",
    "\n",
    "The objective of the second problem is to perform Sentiment analysis from the tweets data collected from the users targeted at various mobile devices.\n",
    "Based on the tweet posted by a user (text), we will classify if the sentiment of the user targeted at a particular mobile device is positive or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nAQDiZHRH0M_"
   },
   "source": [
    "### 1. Read the dataset (tweets.csv) and drop the NA's while reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3eXGIe-SH0NA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CWeWe1eJH0NF"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"tweets.csv\",encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jPJvTjefH0NI"
   },
   "source": [
    "### 2. Preprocess the text and add the preprocessed text in a column with name `text` in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kalya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ToktokTokenizer()\n",
    "stopword_list = stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')\n",
    "nlp = spacy.load('en_core_web_sm', parse=True, tag=True, entity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, is_lower_case=False, remove_digits=False):\n",
    "    try:\n",
    "        #remove_stopwords\n",
    "        tokens = tokenizer.tokenize(text)\n",
    "        tokens = [token.strip() for token in tokens]\n",
    "        if is_lower_case:\n",
    "            filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "        else:\n",
    "            filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "        filtered_text = ' '.join(filtered_tokens)\n",
    "        \n",
    "        #remove_special_characters\n",
    "        pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "        text = re.sub(pattern, '', filtered_text)\n",
    "        \n",
    "        #lemmatize_text\n",
    "        text = nlp(text)\n",
    "        text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "        \n",
    "        #strip_html_tags\n",
    "        soup = BeautifulSoup(text, \"html.parser\")\n",
    "        stripped_text = soup.get_text()\n",
    "        \n",
    "        #remove_accented_chars\n",
    "        text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        return text\n",
    "        \n",
    "    except Exception as e:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = [preprocess(text) for text in df.tweet_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>wesley83 3 g iPhone 3 hrs tweet rise_austin   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>jessedee Know fludapp   Awesome ipadiphone app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>swonderlin not wait iPad 2 also sale SXSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>sxsw hope year   festival   crashy year   iPho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>sxtxstate great stuff Fri SXSW   Marissa Mayer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \\\n",
       "0                                   Negative emotion   \n",
       "1                                   Positive emotion   \n",
       "2                                   Positive emotion   \n",
       "3                                   Negative emotion   \n",
       "4                                   Positive emotion   \n",
       "\n",
       "                                                text  \n",
       "0  wesley83 3 g iPhone 3 hrs tweet rise_austin   ...  \n",
       "1  jessedee Know fludapp   Awesome ipadiphone app...  \n",
       "2          swonderlin not wait iPad 2 also sale SXSW  \n",
       "3  sxsw hope year   festival   crashy year   iPho...  \n",
       "4  sxtxstate great stuff Fri SXSW   Marissa Mayer...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OGWB3P2WH0NY"
   },
   "source": [
    "### 3. Consider only rows having Positive emotion and Negative emotion and remove other rows from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bdgA_8N2H0NY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative emotion', 'Positive emotion',\n",
       "       'No emotion toward brand or product', \"I can't tell\"], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"is_there_an_emotion_directed_at_a_brand_or_product\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Jlu-reIH0Na"
   },
   "outputs": [],
   "source": [
    "df_emotion=df[df[\"is_there_an_emotion_directed_at_a_brand_or_product\"].isin(['Negative emotion', 'Positive emotion'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SotCRvkDH0Nf"
   },
   "source": [
    "### 4. Represent text as numerical data using `CountVectorizer` and get the document term frequency matrix\n",
    "\n",
    "#### Use `vect` as the variable name for initialising CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YcbkY4sgH0Ng"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KyXtZGr-H0Nl"
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z4LUM-XPH0Nn"
   },
   "outputs": [],
   "source": [
    "df_emotion_features = vect.fit_transform(df_emotion[\"text\"])\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array\n",
    "df_emotion_features = df_emotion_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aIdZYxJtH0Nq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3548, 5455)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emotion_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5pxd5fSHH0Nt"
   },
   "source": [
    "### 5. Find number of different words in vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p1DQ2LdNH0Nu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wesley83': 5244,\n",
       " 'iphone': 2581,\n",
       " 'hrs': 2363,\n",
       " 'tweet': 4969,\n",
       " 'rise_austin': 4032,\n",
       " 'dead': 1293,\n",
       " 'nee': 3240,\n",
       " 'upgrade': 5065,\n",
       " 'plugin': 3642,\n",
       " 'station': 4475,\n",
       " 'sxsw': 4617,\n",
       " 'jessedee': 2645,\n",
       " 'know': 2735,\n",
       " 'fludapp': 1859,\n",
       " 'awesome': 501,\n",
       " 'ipadiphone': 2570,\n",
       " 'app': 374,\n",
       " 'likely': 2845,\n",
       " 'appreciate': 398,\n",
       " 'design': 1344,\n",
       " 'also': 298,\n",
       " 'give': 2052,\n",
       " 'free': 1923,\n",
       " 'ts': 4949,\n",
       " 'swonderlin': 4608,\n",
       " 'not': 3310,\n",
       " 'wait': 5180,\n",
       " 'ipad': 2562,\n",
       " 'sale': 4080,\n",
       " 'hope': 2340,\n",
       " 'year': 5405,\n",
       " 'festival': 1801,\n",
       " 'crashy': 1189,\n",
       " 'sxtxstate': 4654,\n",
       " 'great': 2133,\n",
       " 'stuff': 4536,\n",
       " 'fri': 1929,\n",
       " 'marissa': 2999,\n",
       " 'mayer': 3031,\n",
       " 'google': 2089,\n",
       " 'tim': 4832,\n",
       " 'reilly': 3937,\n",
       " 'tech': 4712,\n",
       " 'booksconference': 692,\n",
       " 'amp': 321,\n",
       " 'matt': 3023,\n",
       " 'mullenweg': 3195,\n",
       " 'wordpress': 5341,\n",
       " 'start': 4468,\n",
       " 'ctia': 1226,\n",
       " 'around': 418,\n",
       " 'corner': 1146,\n",
       " 'googleio': 2103,\n",
       " 'hop': 2339,\n",
       " 'skip': 4297,\n",
       " 'jump': 2681,\n",
       " 'good': 2081,\n",
       " 'time': 4834,\n",
       " 'android': 332,\n",
       " 'fan': 1753,\n",
       " 'beautifully': 591,\n",
       " 'smart': 4324,\n",
       " 'simple': 4269,\n",
       " 'idea': 2400,\n",
       " 'rt': 4062,\n",
       " 'madebymany': 2953,\n",
       " 'thenextweb': 4778,\n",
       " 'write': 5369,\n",
       " 'hollergram': 2320,\n",
       " 'httpbitlyieavob': 2373,\n",
       " 'count': 1160,\n",
       " 'day': 1287,\n",
       " 'plus': 3644,\n",
       " 'strong': 4528,\n",
       " 'canadian': 829,\n",
       " 'dollar': 1457,\n",
       " 'mean': 3040,\n",
       " 'stock': 4493,\n",
       " 'apple': 383,\n",
       " 'gear': 2006,\n",
       " 'excited': 1686,\n",
       " 'meet': 3051,\n",
       " 'samsungmobileus': 4086,\n",
       " 'show': 4248,\n",
       " 'sprint': 4447,\n",
       " 'galaxy': 1985,\n",
       " 'still': 4490,\n",
       " 'run': 4071,\n",
       " '21': 61,\n",
       " 'fail': 1744,\n",
       " 'find': 1822,\n",
       " 'impromptu': 2448,\n",
       " 'parties': 3500,\n",
       " 'hurricaneparty': 2388,\n",
       " 'httpbitlygvlrin': 2371,\n",
       " 'til': 4830,\n",
       " 'come': 1023,\n",
       " 'foursquare': 1910,\n",
       " 'up': 5060,\n",
       " 'game': 1988,\n",
       " 'httpjmpgrn7pk': 2375,\n",
       " 'prefer': 3706,\n",
       " 'gowalla': 2118,\n",
       " 'far': 1762,\n",
       " 'best': 617,\n",
       " 'look': 2896,\n",
       " 'date': 1280,\n",
       " 'got': 2114,\n",
       " 'to': 4860,\n",
       " 'love': 2917,\n",
       " 'calendar': 813,\n",
       " 'feature': 1784,\n",
       " 'top': 4883,\n",
       " 'party': 3505,\n",
       " 'case': 850,\n",
       " 'check': 910,\n",
       " 'out': 3429,\n",
       " 'hamsandwich': 2199,\n",
       " 'via': 5127,\n",
       " 'ischafer': 2608,\n",
       " 'gt': 2160,\n",
       " 'httpbitlyaxzwxb': 2369,\n",
       " 'httptinyurlcom4nqv92l': 2379,\n",
       " 'haha': 2189,\n",
       " 'awesomely': 502,\n",
       " 'rad': 3847,\n",
       " 'httpbitlyhtdfim': 2372,\n",
       " 'notice': 3319,\n",
       " 'dst': 1509,\n",
       " 'weekend': 5234,\n",
       " 'many': 2984,\n",
       " 'user': 5088,\n",
       " 'hour': 2352,\n",
       " 'late': 2767,\n",
       " 'sunday': 4567,\n",
       " 'morning': 3172,\n",
       " 'add': 215,\n",
       " 'flight': 1849,\n",
       " 'planely': 3616,\n",
       " 'match': 3020,\n",
       " 'people': 3546,\n",
       " 'planesairport': 3617,\n",
       " 'download': 1483,\n",
       " 'klm': 2730,\n",
       " 'nicely': 3282,\n",
       " 'do': 1444,\n",
       " 'must': 3208,\n",
       " 'malbonster': 2972,\n",
       " 'lovely': 2921,\n",
       " 'review': 4005,\n",
       " 'forbes': 1890,\n",
       " 'holler': 2319,\n",
       " 'gram': 2124,\n",
       " 'httptcog4gzypv': 2378,\n",
       " 'need': 3241,\n",
       " 'buy': 797,\n",
       " 'ipad2': 2564,\n",
       " 'austin': 466,\n",
       " 'sure': 4579,\n",
       " 'store': 4500,\n",
       " 'oh': 3368,\n",
       " 'my': 3214,\n",
       " 'god': 2067,\n",
       " 'pure': 3800,\n",
       " 'unadulterated': 5013,\n",
       " 'easy': 1538,\n",
       " 'browse': 761,\n",
       " 'event': 1656,\n",
       " 'website': 5231,\n",
       " 'okay': 3371,\n",
       " 'really': 3883,\n",
       " 'yay': 5401,\n",
       " 'new': 3263,\n",
       " '11': 17,\n",
       " 'kthxbai': 2739,\n",
       " 'photo': 3575,\n",
       " 'instal': 2512,\n",
       " 'nice': 3281,\n",
       " 'httptumblrcomx6t1pi6av7': 2380,\n",
       " 'enjoy': 1608,\n",
       " 'change': 891,\n",
       " '30': 82,\n",
       " 'forward': 1906,\n",
       " 'see': 4150,\n",
       " 'else': 1581,\n",
       " 'sleeve': 4307,\n",
       " 'laurieshook': 2782,\n",
       " 'smcdallas': 4331,\n",
       " 'pre': 3702,\n",
       " 'we': 5218,\n",
       " 'would': 5357,\n",
       " 'win': 5281,\n",
       " 'result': 3993,\n",
       " 'shameless': 4207,\n",
       " 'promotion': 3769,\n",
       " 'chevysmc': 921,\n",
       " 'michaelpiliero': 3084,\n",
       " 'someone': 4385,\n",
       " 'partnerhub': 3502,\n",
       " 'group': 2145,\n",
       " 'presxsw': 3729,\n",
       " '4sq3': 119,\n",
       " 'like': 2843,\n",
       " 'go': 2065,\n",
       " 'rock': 4041,\n",
       " 'update': 5062,\n",
       " 'push': 3803,\n",
       " 'tonight': 4872,\n",
       " 'httpbitlyetsbzk': 2370,\n",
       " 'keepaustinweird': 2697,\n",
       " 'right': 4023,\n",
       " 'sweeeeet': 4600,\n",
       " 'job': 2654,\n",
       " 'team': 4706,\n",
       " 'there': 4782,\n",
       " 'httptcoa3xvwc6': 2377,\n",
       " 'may': 3029,\n",
       " 'leave': 2806,\n",
       " 'vuvuzela': 5175,\n",
       " 'home': 2327,\n",
       " 'httpitunesapplecomusapphollergramid420666439mt8': 2374,\n",
       " 'mention': 3065,\n",
       " 'ha': 2181,\n",
       " 'first': 1831,\n",
       " 'line': 2852,\n",
       " 'quot': 3841,\n",
       " 'popupquot': 3668,\n",
       " 'planner': 3619,\n",
       " 'eventprof': 1657,\n",
       " 'pcma': 3530,\n",
       " 'engage365': 1601,\n",
       " 'false': 1749,\n",
       " 'alarm': 278,\n",
       " 'circle': 950,\n",
       " 'nowand': 3327,\n",
       " 'probably': 3747,\n",
       " 'ever': 1661,\n",
       " 'link': 2855,\n",
       " 'circles': 951,\n",
       " 'social': 4357,\n",
       " 'weather': 5222,\n",
       " 'greet': 2135,\n",
       " 'sweater': 4599,\n",
       " 'night': 3287,\n",
       " 'put': 3807,\n",
       " 'flash': 1841,\n",
       " 'storequot': 4501,\n",
       " 'downtown': 1486,\n",
       " 'sell': 4166,\n",
       " 'smartcover': 4325,\n",
       " 'open': 3394,\n",
       " 'instant': 2515,\n",
       " 'access': 182,\n",
       " 'get': 2035,\n",
       " 'one': 3383,\n",
       " 'handheld': 2201,\n",
       " 'hobo': 2313,\n",
       " 'drafthouse': 1488,\n",
       " 'launch': 2777,\n",
       " 'shotgun': 4243,\n",
       " 'hooray': 2336,\n",
       " 'opening': 3398,\n",
       " 'popup': 3667,\n",
       " '124': 22,\n",
       " 'wooooo': 5336,\n",
       " 'midnight': 3091,\n",
       " 'talk': 4685,\n",
       " 'effort': 1566,\n",
       " 'allow': 290,\n",
       " 'system': 4663,\n",
       " 'bettercloud': 624,\n",
       " '1st': 54,\n",
       " 'stop': 4498,\n",
       " 'chaos': 894,\n",
       " 'hunt': 2387,\n",
       " 'java': 2633,\n",
       " 'spy': 4448,\n",
       " 'chance': 890,\n",
       " 'omfg': 3376,\n",
       " 'heard': 2249,\n",
       " 'pics': 3586,\n",
       " 'already': 296,\n",
       " 'insane': 2500,\n",
       " 'attend': 451,\n",
       " 'headache': 2240,\n",
       " 'boooo': 697,\n",
       " 'flipboard': 1851,\n",
       " 'develop': 1364,\n",
       " 'version': 5123,\n",
       " 'say': 4101,\n",
       " 'power': 3691,\n",
       " 'sxswi': 4635,\n",
       " 'it': 2612,\n",
       " 'bands': 534,\n",
       " 'food': 1879,\n",
       " 'art': 424,\n",
       " 'ice': 2397,\n",
       " 'cream': 1196,\n",
       " 'nifty': 3286,\n",
       " 'interactive': 2528,\n",
       " 'map': 2985,\n",
       " 'holla': 2318,\n",
       " 'butt': 794,\n",
       " 'here': 2268,\n",
       " 'phone': 3573,\n",
       " 'post': 3683,\n",
       " 'make': 2968,\n",
       " 'connect': 1083,\n",
       " 'network': 3258,\n",
       " 'behave': 601,\n",
       " 'today': 4862,\n",
       " 'crashes': 1186,\n",
       " 'yesterday': 5415,\n",
       " 'ridiculous': 4019,\n",
       " 'hey': 2271,\n",
       " 'peek': 3538,\n",
       " 'space': 4408,\n",
       " 'slate': 4303,\n",
       " 'tomorrow': 4868,\n",
       " 'thing': 4790,\n",
       " 'earth': 1531,\n",
       " 'face': 1735,\n",
       " 'company': 1041,\n",
       " 'sxwsi': 4655,\n",
       " 'thank': 4762,\n",
       " 'speech': 4423,\n",
       " 'showcase': 4249,\n",
       " 'conf': 1067,\n",
       " 'sxswh': 4634,\n",
       " 'sxsh': 4615,\n",
       " 'provide': 3779,\n",
       " 'charger': 897,\n",
       " 'mind': 3103,\n",
       " 'next': 3274,\n",
       " 'xmas': 5390,\n",
       " 'shiny': 4225,\n",
       " 'garyvee': 1996,\n",
       " 'book': 690,\n",
       " 'christmas': 943,\n",
       " 'nerd': 3245,\n",
       " 'yai': 5398,\n",
       " 'ubersocial': 4997,\n",
       " 'include': 2464,\n",
       " 'uberguide': 4996,\n",
       " 'sponsor': 4438,\n",
       " 'cont': 1105,\n",
       " 'fast': 1770,\n",
       " 'fun': 1960,\n",
       " 'future': 1967,\n",
       " 'present': 3720,\n",
       " 'search': 4140,\n",
       " 'local': 2877,\n",
       " 'mobile': 3138,\n",
       " 'headline': 2244,\n",
       " 'musthave': 3209,\n",
       " 'gadget': 1977,\n",
       " 'sxswquot': 4647,\n",
       " 'hmm': 2310,\n",
       " 'could': 1159,\n",
       " 'datavizquot': 1279,\n",
       " 'translate': 4920,\n",
       " 'satanicquot': 4092,\n",
       " 'sayin': 4102,\n",
       " 'checkin': 911,\n",
       " 'month': 3161,\n",
       " 'agoquot': 255,\n",
       " 'in': 2457,\n",
       " 'ok': 3370,\n",
       " 'bizzy': 655,\n",
       " 'tweetquot': 4976,\n",
       " 'think': 4792,\n",
       " 'speakquot': 4418,\n",
       " 'mark': 3003,\n",
       " 'belinsky': 605,\n",
       " '911tweets': 159,\n",
       " 'panel': 3477,\n",
       " 'kawasaki': 2695,\n",
       " 'cs': 1222,\n",
       " 'lewis': 2826,\n",
       " 'level': 2824,\n",
       " 'reason': 3888,\n",
       " 'continue': 1113,\n",
       " 'existence': 1696,\n",
       " 'evidence': 1671,\n",
       " 'godquot': 2069,\n",
       " 'bawl': 576,\n",
       " 'pagemaker': 3467,\n",
       " 'save': 4095,\n",
       " 'applequot': 391,\n",
       " 'jwtatl': 2690,\n",
       " 'enchantment': 1594,\n",
       " 'spark': 4411,\n",
       " 'teamandroid': 4708,\n",
       " 'award': 495,\n",
       " 'read': 3874,\n",
       " 'thought': 4805,\n",
       " 'japan': 2630,\n",
       " 'apac': 370,\n",
       " 'region': 3928,\n",
       " 'deal': 1296,\n",
       " 'earthquake': 1533,\n",
       " 'tsunami': 4951,\n",
       " 'trauma': 4924,\n",
       " 'school': 4122,\n",
       " 'marketing': 3008,\n",
       " 'expert': 1708,\n",
       " 'temporary': 4741,\n",
       " 'def': 1309,\n",
       " 'tent': 4747,\n",
       " 'powerhouse': 3693,\n",
       " 'gym': 2177,\n",
       " '6th': 144,\n",
       " 'congress': 1082,\n",
       " 'along': 293,\n",
       " '10000': 7,\n",
       " 'happy': 2216,\n",
       " 'hipster': 2292,\n",
       " 'support': 4576,\n",
       " 'trend': 4930,\n",
       " 'nerdy': 3252,\n",
       " 'christian': 942,\n",
       " 'devs': 1371,\n",
       " 'want': 5199,\n",
       " 'maybe': 3030,\n",
       " 'wk': 5315,\n",
       " 'together': 4866,\n",
       " 'cool': 1129,\n",
       " 'take': 4676,\n",
       " 'storm': 4504,\n",
       " 'part': 3496,\n",
       " 'haz': 2236,\n",
       " 'ifrom': 2411,\n",
       " 'gr8': 2122,\n",
       " 'stack': 4457,\n",
       " 'mine': 3110,\n",
       " 'no': 3296,\n",
       " 'hassle': 2227,\n",
       " 'all': 286,\n",
       " 'handle': 2204,\n",
       " 'perfectly': 3553,\n",
       " 'smallbiz': 4323,\n",
       " 'play': 3626,\n",
       " 'places': 3610,\n",
       " 'seo': 4174,\n",
       " 'major': 2966,\n",
       " 'south': 4404,\n",
       " 'korean': 2737,\n",
       " 'director': 1403,\n",
       " '130000': 26,\n",
       " 'movie': 3186,\n",
       " 'entirely': 1618,\n",
       " 'beautiful': 590,\n",
       " 'pic': 3582,\n",
       " 'sneaky': 4353,\n",
       " 'usual': 5092,\n",
       " 'beta': 621,\n",
       " 'test': 4752,\n",
       " 'moonbot': 3165,\n",
       " 'studio': 4534,\n",
       " 'louisiana': 2914,\n",
       " 'ton': 4869,\n",
       " 'everything': 1668,\n",
       " 'except': 1682,\n",
       " '64gig': 138,\n",
       " 'wifi': 5271,\n",
       " 'white': 5256,\n",
       " 'manage': 2976,\n",
       " 'jean': 2638,\n",
       " 'configuration': 1072,\n",
       " 'offer': 3358,\n",
       " 'promo': 3767,\n",
       " 'ninjafinder': 3295,\n",
       " 'sucks': 4554,\n",
       " 'poursite': 3690,\n",
       " 'learn': 2798,\n",
       " 'lifechange': 2832,\n",
       " 'impact': 2435,\n",
       " 'real': 3878,\n",
       " 'actual': 208,\n",
       " 'life': 2831,\n",
       " 'bravo': 727,\n",
       " 'lonelyplanet': 2892,\n",
       " 'guide': 2167,\n",
       " 'limited': 2849,\n",
       " 'lp': 2929,\n",
       " 'travel': 4925,\n",
       " 'short': 4238,\n",
       " 'tradeshow': 4911,\n",
       " 'demo': 1331,\n",
       " 'theatre': 4769,\n",
       " 'presenter': 3723,\n",
       " 'use': 5084,\n",
       " 'anyone': 363,\n",
       " 'quick': 3835,\n",
       " 'hundred': 2384,\n",
       " 'ad': 210,\n",
       " 'hoc': 2314,\n",
       " 'cost': 1154,\n",
       " 'monday': 3154,\n",
       " 'barry': 550,\n",
       " 'diller': 1397,\n",
       " 'york': 5422,\n",
       " 'lunch': 2936,\n",
       " 'hotel': 2349,\n",
       " 'six': 4286,\n",
       " 'dirty': 1404,\n",
       " 'martini': 3010,\n",
       " 'seriously': 4179,\n",
       " 'constant': 1095,\n",
       " 'crash': 1184,\n",
       " 'cause': 863,\n",
       " 'lose': 2906,\n",
       " 'schedule': 4117,\n",
       " 'sync': 4660,\n",
       " 'wp7': 5363,\n",
       " 'ready': 3877,\n",
       " 'ur': 5073,\n",
       " 'blogge': 671,\n",
       " 'conflagration': 1076,\n",
       " 'doofusness': 1469,\n",
       " 'attention': 453,\n",
       " 'ers': 1636,\n",
       " 'rumored': 4068,\n",
       " 'lousy': 2916,\n",
       " 'picture': 3587,\n",
       " 'spend': 4428,\n",
       " '1000': 6,\n",
       " 'couple': 1163,\n",
       " 'city': 956,\n",
       " 'block': 667,\n",
       " 'behind': 603,\n",
       " '100s': 8,\n",
       " 'email': 1583,\n",
       " 'compose': 1056,\n",
       " 'reply': 3970,\n",
       " 'protip': 3775,\n",
       " '10': 4,\n",
       " 'ipad2s': 2565,\n",
       " '2s': 77,\n",
       " 'wild': 5273,\n",
       " 'terrible': 4751,\n",
       " 'video': 5135,\n",
       " 'snap': 4350,\n",
       " 'away': 498,\n",
       " 'keynote': 2705,\n",
       " 'slide': 4311,\n",
       " 'southwest': 4407,\n",
       " 'sweet': 4603,\n",
       " '3d': 102,\n",
       " 'ballroom': 531,\n",
       " '35': 96,\n",
       " 'million': 3101,\n",
       " 'mile': 3097,\n",
       " 'per': 3549,\n",
       " 'drive': 1495,\n",
       " 'maps': 2990,\n",
       " 'navigation': 3231,\n",
       " 'grow': 2152,\n",
       " 'band': 533,\n",
       " 'share': 4209,\n",
       " 'track': 4905,\n",
       " 'audience': 459,\n",
       " 'stage': 4459,\n",
       " 'frostwire': 1940,\n",
       " 'available': 488,\n",
       " 'car': 837,\n",
       " 'zimride': 5446,\n",
       " 'etc': 1645,\n",
       " 'ride': 4016,\n",
       " 'shareable': 4210,\n",
       " 'picked': 3584,\n",
       " 'mophie': 3167,\n",
       " 'battery': 568,\n",
       " 'prep': 3715,\n",
       " 'lug': 2935,\n",
       " 'laptop': 2758,\n",
       " 'huge': 2382,\n",
       " 'last': 2765,\n",
       " 'rumor': 4067,\n",
       " 'monger': 3157,\n",
       " 'preview': 3732,\n",
       " 'socbiz': 4356,\n",
       " 'fb': 1782,\n",
       " 'yes': 5414,\n",
       " 'please': 3635,\n",
       " 'build': 777,\n",
       " 'less': 2818,\n",
       " '24': 65,\n",
       " 'big': 634,\n",
       " 'history': 2300,\n",
       " 'this': 4799,\n",
       " 'groupme': 2149,\n",
       " 'sound': 4400,\n",
       " 'incredible': 2467,\n",
       " 'yet': 5416,\n",
       " 'botch': 709,\n",
       " 'timechange': 4835,\n",
       " 'freak': 1922,\n",
       " 'miss': 3119,\n",
       " 'bloody': 675,\n",
       " 'mary': 3012,\n",
       " 'shout': 4247,\n",
       " 'lady': 2748,\n",
       " 'hold': 2316,\n",
       " 'sip': 4279,\n",
       " 'beer': 596,\n",
       " 'cc': 866,\n",
       " 'wish': 5305,\n",
       " 'dyac': 1521,\n",
       " 'stupid': 4541,\n",
       " 'rumors': 4069,\n",
       " 'sign': 4262,\n",
       " 'point': 3651,\n",
       " 'pick': 3583,\n",
       " 'pop': 3661,\n",
       " '15': 33,\n",
       " 'minute': 3116,\n",
       " 'brilliant': 749,\n",
       " 'enlightening': 1610,\n",
       " 'mechanic': 3047,\n",
       " 'presentation': 3721,\n",
       " 'genius': 2028,\n",
       " 'dictaphone': 1378,\n",
       " 'vidcamera': 5134,\n",
       " 'wow': 5359,\n",
       " 'cerebellum': 880,\n",
       " 'charge': 896,\n",
       " 'personal': 3561,\n",
       " 'kype': 2742,\n",
       " 'geolocation': 2032,\n",
       " 'release': 3946,\n",
       " 'background': 513,\n",
       " 'patch': 3516,\n",
       " 'batterykiller': 569,\n",
       " 'live': 2865,\n",
       " 'rsvp': 4061,\n",
       " 'sundayswaggereventbritecom': 4568,\n",
       " '320': 95,\n",
       " 'scoremore': 4130,\n",
       " 'bizzyquot': 656,\n",
       " 'course': 1165,\n",
       " 'temp': 4737,\n",
       " 'texas': 4756,\n",
       " 'understand': 5024,\n",
       " 'concept': 1062,\n",
       " 'corral': 1151,\n",
       " 'cattle': 862,\n",
       " 'pickmeupanipad2': 3585,\n",
       " 'let': 2820,\n",
       " 'something': 4386,\n",
       " 'retail': 3995,\n",
       " 'near': 3237,\n",
       " 'keep': 2696,\n",
       " 'surprise': 4584,\n",
       " 'town': 4903,\n",
       " 'cnet': 993,\n",
       " 'ipads': 2577,\n",
       " 'example': 1680,\n",
       " 'lay': 2787,\n",
       " 'register': 3929,\n",
       " 'checkout': 915,\n",
       " 'gswsxsw': 2159,\n",
       " 'launchquot': 2780,\n",
       " 'traffic': 4912,\n",
       " 'noon': 3306,\n",
       " 'fresh': 1928,\n",
       " 'shipment': 4227,\n",
       " 'pretty': 3730,\n",
       " 'finger': 1826,\n",
       " 'cross': 1210,\n",
       " 'technew': 4721,\n",
       " 'set': 4189,\n",
       " 'tech_news': 4714,\n",
       " 'lt': 2930,\n",
       " 'true': 4941,\n",
       " 'loathe': 2875,\n",
       " 'blogs': 674,\n",
       " 'atx': 457,\n",
       " 'mall': 2973,\n",
       " '10x': 16,\n",
       " 'crowd': 1211,\n",
       " 'fake': 1747,\n",
       " 'fucking': 1951,\n",
       " 'donglequot': 1463,\n",
       " 'makeshift': 2970,\n",
       " 'kid': 2712,\n",
       " 'me': 3038,\n",
       " 'amazing': 307,\n",
       " 'fanboy': 1755,\n",
       " 'shit': 4230,\n",
       " 'temptation': 4743,\n",
       " 'control': 1116,\n",
       " 'viewio': 5140,\n",
       " 'office': 3359,\n",
       " 'news': 3266,\n",
       " 'you': 5423,\n",
       " 'will': 5275,\n",
       " '150': 34,\n",
       " 'ill': 2418,\n",
       " 'atsxsw': 447,\n",
       " 'software': 4372,\n",
       " 'development': 1367,\n",
       " 'work': 5343,\n",
       " 'overheard': 3443,\n",
       " 'relax': 3944,\n",
       " 'computerquot': 1059,\n",
       " 'agree': 256,\n",
       " 'arg': 411,\n",
       " 'hate': 2228,\n",
       " 'blackberry': 659,\n",
       " 'backquot': 516,\n",
       " 'shock': 4234,\n",
       " 'technology': 4725,\n",
       " 'hear': 2248,\n",
       " 'conferencesquot': 1070,\n",
       " 'everbody': 1662,\n",
       " 'medium': 3050,\n",
       " 'revolution': 4007,\n",
       " 'well': 5241,\n",
       " 'long': 2893,\n",
       " 'rather': 3867,\n",
       " 'agileagency': 252,\n",
       " 'knackere': 2731,\n",
       " 'timeline': 4836,\n",
       " 'smash': 4330,\n",
       " 'partytweet': 3508,\n",
       " 'bed': 594,\n",
       " 'mdw': 3037,\n",
       " 'second': 4147,\n",
       " 'halfway': 2196,\n",
       " 'even': 1654,\n",
       " 'board': 685,\n",
       " 'plane': 3615,\n",
       " 'amateurhour': 306,\n",
       " 'jobs_co': 2656,\n",
       " 'final': 1819,\n",
       " 'doodles': 1468,\n",
       " 'googledoodle': 2100,\n",
       " 'trip': 4936,\n",
       " 'aclu': 194,\n",
       " '80': 150,\n",
       " 'laugh': 2776,\n",
       " 'week': 5233,\n",
       " 'hauling': 2230,\n",
       " 'macbook': 2945,\n",
       " 'everywhere': 1670,\n",
       " 'shoulder': 4246,\n",
       " 'rub': 4064,\n",
       " 'attendee': 452,\n",
       " 'qr': 3814,\n",
       " 'code': 1005,\n",
       " 'reader': 3875,\n",
       " 'us': 5078,\n",
       " 'image': 2426,\n",
       " 'badge': 520,\n",
       " 'optiscan': 3408,\n",
       " 'now': 3326,\n",
       " 'four': 1909,\n",
       " 'lego': 2810,\n",
       " 'pit': 3601,\n",
       " 'replace': 3966,\n",
       " 'recharge': 3896,\n",
       " 'price': 3735,\n",
       " 'crap': 1180,\n",
       " 'samsung': 4085,\n",
       " 'bad': 519,\n",
       " 'qs': 3818,\n",
       " 'process': 3749,\n",
       " 'poopoo': 3659,\n",
       " 'early': 1526,\n",
       " 'creativequot': 1200,\n",
       " 'busy': 792,\n",
       " 'gamestorme': 1992,\n",
       " 'try': 4947,\n",
       " 'balance': 527,\n",
       " 'vs': 5171,\n",
       " 'suck': 4551,\n",
       " 'airplane': 270,\n",
       " 'mode': 3142,\n",
       " '100': 5,\n",
       " 'winning': 5291,\n",
       " 'precommerce': 3704,\n",
       " 'watch': 5208,\n",
       " 'ipadmadness': 2573,\n",
       " 'shop': 4237,\n",
       " 'core': 1145,\n",
       " 'action': 201,\n",
       " 'celebrate': 868,\n",
       " 'beauty': 592,\n",
       " 'web': 5223,\n",
       " 'msft': 3192,\n",
       " 'ie9': 2409,\n",
       " 'html5': 2366,\n",
       " 'money': 3156,\n",
       " 'relief': 3951,\n",
       " '2quot': 76,\n",
       " 'improve': 2449,\n",
       " 'beyond': 629,\n",
       " 'positive': 3678,\n",
       " 'world': 5346,\n",
       " 'earthhour': 1532,\n",
       " '60': 136,\n",
       " 'bing': 641,\n",
       " 'bettersearch': 626,\n",
       " 'shot': 4242,\n",
       " 'success': 4547,\n",
       " 'structure': 4529,\n",
       " 'potentially': 3688,\n",
       " 'high': 2278,\n",
       " 'margin': 2997,\n",
       " 'cpa': 1175,\n",
       " 'model': 3143,\n",
       " 'qagb': 3811,\n",
       " 'impulsive': 2454,\n",
       " 'friend': 1934,\n",
       " 'too': 4874,\n",
       " 'gen': 2022,\n",
       " '32': 94,\n",
       " 'gb': 2004,\n",
       " 'buying': 800,\n",
       " 'geekdate': 2010,\n",
       " 'rsq': 4060,\n",
       " 'tuxedo': 4963,\n",
       " 'hoursquot': 2353,\n",
       " 'exciting': 1688,\n",
       " 'can': 827,\n",
       " 'certain': 882,\n",
       " 'meeting': 3053,\n",
       " 'hello': 2263,\n",
       " 'charles': 900,\n",
       " 'chen': 919,\n",
       " 'androidchromeos': 333,\n",
       " 'booth': 700,\n",
       " 'exhibit': 1693,\n",
       " 'hall': 2197,\n",
       " '1pm': 53,\n",
       " 'guess': 2164,\n",
       " 'desperate': 1354,\n",
       " 'location': 2880,\n",
       " 'consider': 1092,\n",
       " 'pro': 3745,\n",
       " 'fly': 1863,\n",
       " 'solo': 4378,\n",
       " 'daily': 1254,\n",
       " 'follow': 1872,\n",
       " 'appleatxdt': 386,\n",
       " 'seem': 4152,\n",
       " 'battlela': 572,\n",
       " 'secret': 4148,\n",
       " 'batphone': 566,\n",
       " 'tv': 4964,\n",
       " 'league': 2794,\n",
       " 'extraordinary': 1726,\n",
       " 'hacker': 2185,\n",
       " 'lxh': 2940,\n",
       " 'chunky': 947,\n",
       " 'element': 1577,\n",
       " 'generous': 2027,\n",
       " 'clarity': 960,\n",
       " 'trump': 4943,\n",
       " 'density': 1339,\n",
       " 'tap': 4687,\n",
       " 'quality': 3823,\n",
       " 'quantity': 3824,\n",
       " 'tapworthy': 4688,\n",
       " 'designing': 1349,\n",
       " 'interfaces': 2532,\n",
       " 'schemas': 4120,\n",
       " 'digital': 1392,\n",
       " 'sing': 4275,\n",
       " 'guitar': 2171,\n",
       " 'record': 3906,\n",
       " 'vid': 5133,\n",
       " 'cnn': 994,\n",
       " 'cnngrill': 995,\n",
       " 'content': 1107,\n",
       " 'nut': 3339,\n",
       " 'another': 349,\n",
       " 'docomo': 1447,\n",
       " 'introduce': 2545,\n",
       " 'jpmobilesummit': 2672,\n",
       " 'jeez': 2641,\n",
       " 'guy': 2174,\n",
       " 'dunno': 1518,\n",
       " 'gold': 2076,\n",
       " 'realize': 3881,\n",
       " 'unjobsaesthetic': 5039,\n",
       " 'begins': 599,\n",
       " 'wins': 5293,\n",
       " 'tc': 4699,\n",
       " 'begin': 598,\n",
       " 'techcrunch': 4715,\n",
       " 'winssxsw': 5294,\n",
       " 'sum': 4563,\n",
       " 'pm': 3646,\n",
       " 'badgeless': 521,\n",
       " 'drinks': 1494,\n",
       " 'head': 2239,\n",
       " 'googlesponsored': 2109,\n",
       " 'semantic': 4169,\n",
       " 'fogo': 1870,\n",
       " 'de': 1292,\n",
       " 'cho': 935,\n",
       " 'swag': 4596,\n",
       " 'timing': 4839,\n",
       " 'brand': 726,\n",
       " 'winner': 5289,\n",
       " 'pnid': 3647,\n",
       " 'exhibitor': 1694,\n",
       " 'capture': 836,\n",
       " 'experience': 1705,\n",
       " 'retrollect': 3997,\n",
       " 'disc': 1412,\n",
       " 'popular': 3665,\n",
       " 'fantastic': 1760,\n",
       " 'bummer': 784,\n",
       " 'crackberry': 1178,\n",
       " 'accessory': 185,\n",
       " 'followed': 1873,\n",
       " 'closely': 980,\n",
       " 'margarita': 2996,\n",
       " 'fav': 1777,\n",
       " 'fall': 1748,\n",
       " 'bit': 648,\n",
       " 'throw': 4814,\n",
       " 'speakeasy': 4417,\n",
       " 'way': 5216,\n",
       " 'figure': 1811,\n",
       " 'replacement': 3967,\n",
       " 'stream': 4516,\n",
       " 'inane': 2458,\n",
       " 'surely': 4580,\n",
       " 'southby': 4405,\n",
       " 'hot': 2348,\n",
       " 'spot': 4441,\n",
       " 'spots': 4442,\n",
       " 'focus': 1867,\n",
       " 'bridge': 743,\n",
       " 'digitalphysical': 1395,\n",
       " 'divide': 1437,\n",
       " 'eg': 1567,\n",
       " 'streetview': 4519,\n",
       " 'hotpot': 2350,\n",
       " 'autonomous': 486,\n",
       " 'driving': 1498,\n",
       " 'folk': 1871,\n",
       " 'blast': 662,\n",
       " 'customer': 1242,\n",
       " 'alcoholics': 281,\n",
       " 'call': 816,\n",
       " 'enable': 1592,\n",
       " 'rest': 3988,\n",
       " 'austinbound': 469,\n",
       " 'list': 2858,\n",
       " 'ntn': 3333,\n",
       " 'apps': 403,\n",
       " 'help': 2264,\n",
       " 'playing': 3632,\n",
       " 'field': 1807,\n",
       " 'hitlantis': 2304,\n",
       " 'song': 4388,\n",
       " 'explorer': 1716,\n",
       " 'hitlantiscom': 2305,\n",
       " 'musicviz': 3204,\n",
       " 'willing': 5277,\n",
       " 'pay': 3524,\n",
       " 'premium': 3713,\n",
       " 'dm': 1443,\n",
       " 'atl': 444,\n",
       " 'akqa': 274,\n",
       " 'interface': 2531,\n",
       " 'callback': 818,\n",
       " 'principle': 3738,\n",
       " 'mediamarkete': 3049,\n",
       " 'person': 3560,\n",
       " 'front': 1937,\n",
       " 'outside': 3437,\n",
       " 'word': 5339,\n",
       " 'circlesquot': 952,\n",
       " 'forget': 1896,\n",
       " 'air': 267,\n",
       " 'full': 1955,\n",
       " 'underway': 5026,\n",
       " 'tell': 4736,\n",
       " 'intermittent': 2533,\n",
       " 'brick': 741,\n",
       " 'labs': 2746,\n",
       " 'source': 4403,\n",
       " 'coder': 1006,\n",
       " 'meetup': 3054,\n",
       " 'cupcake': 1231,\n",
       " 'windows': 5284,\n",
       " 'addition': 220,\n",
       " 'afraid': 241,\n",
       " 'omg': 3377,\n",
       " 'iphone4': 2582,\n",
       " 'ipod': 2594,\n",
       " 'tab': 4665,\n",
       " 'techgeek': 4717,\n",
       " 'golden': 2077,\n",
       " ...}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dwtgjTBeH0Ny"
   },
   "source": [
    "#### Tip: To see all available functions for an Object use dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2n_iCcTNH0N0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ShA6D8jKH0N5"
   },
   "source": [
    "### 6. Find out how many Positive and Negative emotions are there.\n",
    "\n",
    "Hint: Use value_counts on that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q7LAl5pzH0N6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive emotion    2978\n",
       "Negative emotion     570\n",
       "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emotion[\"is_there_an_emotion_directed_at_a_brand_or_product\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IUvgj0FoH0N9"
   },
   "source": [
    "### 7. Change the labels for Positive and Negative emotions as 1 and 0 respectively and store in a different column in the same dataframe named 'Label'\n",
    "\n",
    "Hint: use map on that column and give labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YftKwFv7H0N9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kalya\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_emotion['label']=np.where(df_emotion[\"is_there_an_emotion_directed_at_a_brand_or_product\"]=='Positive emotion',1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>wesley83 3 g iPhone 3 hrs tweet rise_austin   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>jessedee Know fludapp   Awesome ipadiphone app...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>swonderlin not wait iPad 2 also sale SXSW</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>sxsw hope year   festival   crashy year   iPho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>sxtxstate great stuff Fri SXSW   Marissa Mayer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \\\n",
       "0                                   Negative emotion   \n",
       "1                                   Positive emotion   \n",
       "2                                   Positive emotion   \n",
       "3                                   Negative emotion   \n",
       "4                                   Positive emotion   \n",
       "\n",
       "                                                text  label  \n",
       "0  wesley83 3 g iPhone 3 hrs tweet rise_austin   ...      0  \n",
       "1  jessedee Know fludapp   Awesome ipadiphone app...      1  \n",
       "2          swonderlin not wait iPad 2 also sale SXSW      1  \n",
       "3  sxsw hope year   festival   crashy year   iPho...      0  \n",
       "4  sxtxstate great stuff Fri SXSW   Marissa Mayer...      1  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_emotion.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3YErwYLCH0N_"
   },
   "source": [
    "### 8 Define the feature set (independent variable or X) to be `text` column and `labels` as target (or dependent variable)  and divide into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_emotion_features\n",
    "Y=df_emotion['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lNkwrGgEH0OA"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#Split data into Train and Test 70:30 respectively)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q5nlCuaaH0OD"
   },
   "source": [
    "## 9. **Predicting the sentiment:**\n",
    "\n",
    "\n",
    "### Use Naive Bayes and Logistic Regression and their accuracy scores for predicting the sentiment of the given text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2AbVYssaH0OE"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as lr\n",
    "from sklearn.naive_bayes import GaussianNB as nb\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ktXrLhmOH0Of"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=5000, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = lr(solver='lbfgs' , max_iter=5000 , multi_class='multinomial')\n",
    "lr_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8769953051643192"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.score(x_test , y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr=lr_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.41      0.52       170\n",
      "           1       0.90      0.97      0.93       895\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      1065\n",
      "   macro avg       0.79      0.69      0.72      1065\n",
      "weighted avg       0.86      0.88      0.86      1065\n",
      "\n",
      "[[ 70 100]\n",
      " [ 31 864]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred_lr))\n",
    "print(metrics.confusion_matrix(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "clv2X0kKH0Ok"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model = nb()\n",
    "nb_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K86LRMfdH0Ou"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7295774647887324"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model.score(x_test , y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nb=nb_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.41      0.52       170\n",
      "           1       0.90      0.97      0.93       895\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      1065\n",
      "   macro avg       0.79      0.69      0.72      1065\n",
      "weighted avg       0.86      0.88      0.86      1065\n",
      "\n",
      "[[ 70 100]\n",
      " [ 31 864]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred_lr))\n",
    "print(metrics.confusion_matrix(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sw-0B33tH0Ox"
   },
   "source": [
    "## 10. Create a function called `tokenize_predict` which can take count vectorizer object as input and prints the accuracy for x (text) and y (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_emotion['text'], df_emotion['label'], test_size=0.30, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "okCTOs1TH0Oy"
   },
   "outputs": [],
   "source": [
    "def tokenize_test(vect):\n",
    "    x_train_dtm = vect.fit_transform(x_train)\n",
    "    print('Features: ', x_train_dtm.shape[1])\n",
    "    x_test_dtm = vect.transform(x_test)\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(x_train_dtm, y_train)\n",
    "    y_pred_class = nb.predict(x_test_dtm)\n",
    "    print('Accuracy: ', metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  4509\n",
      "Accuracy:  0.8741784037558685\n"
     ]
    }
   ],
   "source": [
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JxZ8jfPEH0O0"
   },
   "source": [
    "### 11 Create a count vectorizer function which includes n_grams = 1,2  and pass it to tokenize_predict function to print the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kdCyAN_IH0O0"
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = None, \\\n",
    "                             ngram_range=(1,2)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  19942\n",
      "Accuracy:  0.8769953051643192\n"
     ]
    }
   ],
   "source": [
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "axepytmgH0O4"
   },
   "source": [
    "### Q 12 Create a count vectorizer function with stopwords = 'english'  and pass it to tokenize_predict function to print the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HToGkq7vH0O4"
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = 'english',   \\\n",
    "                             max_features = None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  4338\n",
      "Accuracy:  0.8685446009389671\n"
     ]
    }
   ],
   "source": [
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iOIlJRxoH0O7"
   },
   "source": [
    "### Q 13 Create a count vectorizer function with stopwords = 'english' and max_features =300  and pass it to tokenize_predict function to print the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6fUhff-oH0O8"
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = 'english',   \\\n",
    "                             max_features = 300) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  300\n",
      "Accuracy:  0.8169014084507042\n"
     ]
    }
   ],
   "source": [
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S2KZNWVkH0PA"
   },
   "source": [
    "### Q 14 Create a count vectorizer function with n_grams = 1,2  and max_features = 15000  and pass it to tokenize_predict function to print the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3v9XD082H0PB"
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 15000, ngram_range=(1,2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  15000\n",
      "Accuracy:  0.8788732394366198\n"
     ]
    }
   ],
   "source": [
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "We3JK_SRH0PO"
   },
   "source": [
    "### Q. 15 -Create a count vectorizer function with n_grams = 1,2  and include terms that appear at least 2 times (min_df = 2)  and pass it to tokenize_predict function to print the accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fUHrfDCyH0PP"
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = None, ngram_range=(1,2), min_df=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3H4k_lVZH0PS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  5869\n",
      "Accuracy:  0.863849765258216\n"
     ]
    }
   ],
   "source": [
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "R8_Internal_Lab_Questions.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
